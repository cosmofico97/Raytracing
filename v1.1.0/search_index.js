var documenterSearchIndex = {"docs":
[{"location":"interpreter/","page":"Interpreter for the Scene File","title":"Interpreter for the Scene File","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"interpreter/#Scene-Files","page":"Interpreter for the Scene File","title":"Scene Files","text":"","category":"section"},{"location":"interpreter/#Basic-functions","page":"Interpreter for the Scene File","title":"Basic functions","text":"","category":"section"},{"location":"interpreter/","page":"Interpreter for the Scene File","title":"Interpreter for the Scene File","text":"Raytracing.Interpreter.isdigit\nRaytracing.Interpreter.isdecimal\nRaytracing.Interpreter.isalpha\nRaytracing.Interpreter.isalnum\nRaytracing.Interpreter.close_bracket","category":"page"},{"location":"interpreter/#Raytracing.Interpreter.isdigit","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.isdigit","text":"isdigit(a::String) :: Bool\n\nReturn true if a is a sigle digit, false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.isdecimal","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.isdecimal","text":"isdecimal(a::String) :: Bool\n\nReturn true if a is an integer number, false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.isalpha","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.isalpha","text":"isalpha(a::String) :: Bool\n\nReturn true if a is a string made only of the 26 english letters (capitalized or not) and/or the underscore symbol \"_\" , false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.isalnum","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.isalnum","text":"isalnum(a::String) :: Bool\n\nReturn true if a is a string made only of the 26 english letters (capitalized or not), the underscore symbol \"_\" and the 10 basic digits, false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.close_bracket","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.close_bracket","text":" closed_bracket(open::String) :: String\n\nGiven in input a string of an open braket ([\"{\", \"[\", \"(\", \"<\"]) return the corresponding closed one ([\"}\", \"]\", \")\", \">\"]).\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#SourceLocation-and-Tokens","page":"Interpreter for the Scene File","title":"SourceLocation and Tokens","text":"","category":"section"},{"location":"interpreter/","page":"Interpreter for the Scene File","title":"Interpreter for the Scene File","text":"Raytracing.Interpreter.SourceLocation\nRaytracing.Interpreter.KeywordEnum\nRaytracing.Interpreter.Token\nRaytracing.Interpreter.KeywordToken\nRaytracing.Interpreter.IdentifierToken\nRaytracing.Interpreter.StringToken\nRaytracing.Interpreter.LiteralNumberToken\nRaytracing.Interpreter.SymbolToken\nRaytracing.Interpreter.StopToken\nRaytracing.Interpreter.GrammarError","category":"page"},{"location":"interpreter/#Raytracing.Interpreter.SourceLocation","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.SourceLocation","text":"SourceLocation(file_name::String, line_num::Int64, col_num::Int64)\n\nA specific position in a source file.\n\nArguments\n\nfile_name::String : the name of the file, or the empty string if there is no  file associated with this location (e.g., because the source code was provided as  a memory stream, or through a network connection)\nline_num::Int64 : number of the line (starting from 1)\ncol_num::Int64 : number of the column (starting from 1)\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.KeywordEnum","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.KeywordEnum","text":" @enum KeywordEnum\n\nEnumeration for all the possible keywords recognized by the lexer:\n\n|:-----------------:|:-----------------:|:----------------------:|\n| NEW = 1           | PIGMENT = 20      | TRANSFORMATION = 40    |\n| FLOAT = 2         | UNIFORM = 21      | IDENTITY = 41          |\n| STRING = 3        | CHECKERED = 22    | TRANSLATION = 42       |\n| VECTOR = 4        | IMAGE = 23        | ROTATION_X = 43        |\n| COLOR = 5         |                   | ROTATION_Y = 44        |\n| MATERIAL = 6      |                   | ROTATION_Z = 45        |\n| POINTLIGHT = 7    |                   | SCALING = 46           |\n|                   |                   |                        |\n|:-----------------:|:-----------------:|:----------------------:|\n| BRDFS = 10        | CAMERA = 30       | BOOL = 50              |\n| DIFFUSE = 11      | ORTHOGONAL = 31   | TRUE = 51              |\n| SPECULAR = 12     | PERSPECTIVE = 32  | FALSE = 52             |\n|                   |                   |                        |\n|                   |                   |                        |\n|:-----------------:|:-----------------:|:----------------------:|\n| PLANE = 61        | PRINT = 71        |                        |\n| SPHERE = 62       | ASSERT = 72         |                        |\n|                   |                   |                        |\n|                   |                   |                        |\n|                   |                   |                        |\n|:-----------------:|:-----------------:|:----------------------:|\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.Token","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.Token","text":"Token(\n      location::SourceLocation,\n      value::Union{  \n           KeywordToken, \n           IdentifierToken, \n           StringToken,\n           LiteralNumberToken,\n           SymbolToken, \n           StopToken}\n      )\n\nA lexical token, used when parsing a scene file.\n\nArguments\n\nlocation::SourceLocation: location of the last char read\nvalue : one of the basic 6 token types:\nKeywordToken\nIdentifierToken\nStringToken\nLiteralNumberToken\nSymbolToken\nStopToken\n\nSee also: SourceLocation\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.KeywordToken","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.KeywordToken","text":"KeywordToken(keyword::KeywordEnum)\n\nA token containing a keyword of the Photorealistic Object Applications Language.\n\nSee also: KeywordEnum\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.IdentifierToken","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.IdentifierToken","text":"IdentifierToken(identifier::String)\n\nA token containing an identifier, i.e. a name of a variable.\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.StringToken","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.StringToken","text":" StringToken(string::String)\n\nA token containing a literal string, i.e. a sentence placed inside two  double quotes (\"...\") symbols.\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.LiteralNumberToken","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.LiteralNumberToken","text":"LiteralNumberToken(number::Float64)\n\nA token containing a literal number.\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.SymbolToken","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.SymbolToken","text":"SymbolToken(symbol::String)\n\nA token containing a recognised symbol by the Photorealistic Object  Applications Language.\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.StopToken","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.StopToken","text":"StopToken()\n\nA token signalling the end of a file.\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.GrammarError","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.GrammarError","text":" GrammarError <: Exception(\n      location::SourceLocation\n      message::String\n )\n\nAn error found by the lexer/parser while reading a scene file.\n\nArguments\n\nlocation::SourceLocation : location of the last char read\nmessage::String : a user-frendly error message\n\nSee also: SourceLocation\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Parsing-and-readingTokens","page":"Interpreter for the Scene File","title":"Parsing and readingTokens","text":"","category":"section"},{"location":"interpreter/","page":"Interpreter for the Scene File","title":"Interpreter for the Scene File","text":"Raytracing.Interpreter.InputStream\nRaytracing.Interpreter.update_pos\nRaytracing.Interpreter.read_char\nRaytracing.Interpreter.unread_char\nRaytracing.Interpreter.skip_whitespaces_and_comments\nRaytracing.Interpreter.parse_string_token\nRaytracing.Interpreter.parse_float_token\nRaytracing.Interpreter.parse_keyword_or_identifier_token\nRaytracing.Interpreter.read_token\nRaytracing.Interpreter.unread_token","category":"page"},{"location":"interpreter/#Raytracing.Interpreter.InputStream","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.InputStream","text":"InputStream(\n    stream::IO,\n    location::SourceLocation,\n    saved_char::String,\n    saved_location::SourceLocation,\n    tabulations::Int64,\n    saved_token::Union{Token, Nothing},\n)\n\nA high-level wrapper around a stream, used to parse scene files This class implements a wrapper around a stream, with the following  additional capabilities:\n\nIt tracks the line number and column number;\nIt permits to \"un-read\" characters and tokens.\n\nArguments\n\nstream::IO : stream to read from\nlocation::SourceLocation : location of the last char read\nsaved_char::String : the last char read\nsaved_location::SourceLocation : location where saved_char is in the file\ntabulations::Int64: number of space a tab command gives\nsaved_token::Union{Token, Nothing} : the last token found\n\nConstructors\n\nInputStream(         stream::IO,          filename::String = \"\",          tabulations::Int64 = 8         ) = new(              stream,               SourceLocation(filename, 1, 1),               \"\",               SourceLocation(file_name, 1, 1),               tabulations,               nothing              )\nInputStream(         s::IO,         l::SourceLocation,         sc::String,         sl::SourceLocation,         t::Int64,         st::Union{Token, Nothing}         ) = new(s,l,sc,sl,t,st)\n\nSee also: SourceLocation, Token\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.update_pos","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.update_pos","text":"update_pos(inputstream::InputStream, ch::String)\n\nUpdate location after having read ch from the stream.\n\nSee also: SourceLocation\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.read_char","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.read_char","text":" read_char(inputstream::InputStream) :: String\n\nRead a new character from the stream. Calls internally update_pos.\n\nSee also: InputStream, unread_char\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.unread_char","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.unread_char","text":" unread_char(inputstream::InputStream, ch::String)\n\nPush a character back to the stream.\n\nSee also: InputStream, read_char\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.skip_whitespaces_and_comments","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.skip_whitespaces_and_comments","text":" skip_whitespaces_and_comments(inputstream::InputStream)\n\nKeep reading characters until a non-whitespace/non-comment character is found. Calls internally read_char and unread_char, and it's used inside the main function read_token.\n\nSee also: InputStream\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_string_token","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_string_token","text":" parse_string_token(\n      inputstream::InputStream,\n      token_location::SourceLocation\n      ) ::Token(::SourceLocation, ::StringToken)\n\nParse a string from the given input inputstream and return that string inside a Token(::SourceLocation, ::StringToken) with the given token_location, throwing GrammarError in case of exception. Works calling read_char, and it's used inside the main function read_token.\n\nSee also: InputStream, SourceLocation Token, StringToken, GrammarError\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_float_token","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_float_token","text":" parse_float_token(\n      inputstream::InputStream, \n      first_char::String, \n      token_location::SourceLocation\n      ) :: Token{SourceLocation, LiteralNumberToken}\n\nParse a float from the given input inputstream and return that float inside a Token(::SourceLocation, ::LiteralNumberToken) with the given token_location, throwing GrammarError in case of exception. Works calling read_char and unread_char, and it's used inside the main function read_token.\n\nSee also: InputStream, SourceLocation Token, LiteralNumberToken, GrammarError\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_keyword_or_identifier_token","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_keyword_or_identifier_token","text":" parse_keyword_or_identifier_token(\n      inputstream::InputStream,\n      first_char::String,\n      token_location::SourceLocation\n      ) ::Union{\n                Token(::SourceLocation, ::KeywordToken),\n                Token(::SourceLocation, ::IdentifierToken)\n                }\n\nParse a keyword or an identifier from the given input inputstream and return that keyword/identifier inside respectively a Token(::SourceLocation, ::KeyworkdToken)  or a Token(::SourceLocation, ::IdentifierToken) with the given token_location,  throwing GrammarError in case of exception. Works calling read_char and unread_char, and it's used inside the main function read_token.\n\nSee also: InputStream, SourceLocation Token, LiteralNumberToken, GrammarError\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.read_token","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.read_token","text":" read_token(inputstream::InputStream) :: Token\n\nRead one of the 6 basic tokens from the stream, raising GrammarError if a  lexical error is found. Calls internally the following functions:\n\nskip_whitespaces_and_comments\nread_char\nisdecimal\nisalpha\ncopy(::SourceLocation)\nparse_string_token for StringToken\nparse_float_token for LiteralNumberToken\nparse_keyword_or_identifier_token for KeywordToken and IdentifierToken\n\nSee also: InputStream, Token, SymbolToken,  StopToken, GrammarError,\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.unread_token","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.unread_token","text":"unread_token(inputstream::InputStream, token::Token)\n\nMake as if token were never read from inputstream.\n\nSee also: InputStream, Token, read_token\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Scene-and-basic-parsing-scene-functions","page":"Interpreter for the Scene File","title":"Scene and basic parsing scene functions","text":"","category":"section"},{"location":"interpreter/","page":"Interpreter for the Scene File","title":"Interpreter for the Scene File","text":"Raytracing.Interpreter.Scene\nRaytracing.Interpreter.expect_symbol\nRaytracing.Interpreter.expect_keywords\nRaytracing.Interpreter.expect_number\nRaytracing.Interpreter.expect_bool\nRaytracing.Interpreter.expect_string\nRaytracing.Interpreter.expect_identifier\nRaytracing.Interpreter.parse_vector\nRaytracing.Interpreter.parse_color\nRaytracing.Interpreter.parse_pigment\nRaytracing.Interpreter.parse_brdf\nRaytracing.Interpreter.parse_material\nRaytracing.Interpreter.parse_transformation\nRaytracing.Interpreter.parse_pointlight\nRaytracing.Interpreter.parse_camera\nRaytracing.Interpreter.return_token_value\nRaytracing.Interpreter.assert\nRaytracing.Interpreter.parse_scene","category":"page"},{"location":"interpreter/#Raytracing.Interpreter.Scene","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.Scene","text":" Scene(\n      materials::Dict{String, Material} = Dict{String, Material}(),\n      world::World = World(),\n      camera::Union{Camera, Nothing} = nothing,\n\n      float_variables::Dict{String, Float64} = Dict{String, Float64}(),\n      string_variables::Dict{String, String} = Dict{String, String}(),\n      bool_variables::Dict{String, Bool} = Dict{String, Bool}(),\n      vector_variables::Dict{String,Vec} = Dict{String,Vec}(),\n      color_variables::Dict{String,RGB{Float32}} = Dict{String,RGB{Float32}}(),\n      pigment_variables::Dict{String,Pigment} = Dict{String,Pigment}(),\n      brdf_variables::Dict{String,BRDF} = Dict{String,BRDF}(),\n      transformation_variables::Dict{String,Transformation} = Dict{String,Transformation}(),\n\n      variable_names::Set{String} = Set{String}(),\n      overridden_variables::Set{String} = Set{String}(),\n )\n\nA scene read from a scene file.\n\nSee also: Material, World, Camera, Vec, Pigment, BRDF, Transformation\n\n\n\n\n\n","category":"type"},{"location":"interpreter/#Raytracing.Interpreter.expect_symbol","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.expect_symbol","text":" expect_symbol(inputstream::InputStream, symbol::String)\n expect_symbol(inputstream::InputStream, vec_symbol::Vector{String}) :: String\n\nRead a token from inputstream and check that its type is SymbolToken  and its value is symbol(first method) or a value inside vec_symbol (second method, and return it), throwing GrammarError otherwise. Call internally read_token.\n\nSee also: InputStream, KeywordEnum, SymbolToken\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.expect_keywords","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.expect_keywords","text":" expect_keywords(inputstream::InputStream, keywords::Vector{KeywordEnum}) :: KeywordEnum\n\nRead a token from inputstream and check that its type is KeywordToken  and its value is one of the keywords in keywords, throwing GrammarError otherwise. Call internally read_token.\n\nSee also: InputStream, KeywordEnum, KeywordToken\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.expect_number","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.expect_number","text":" expect_number(inputstream::InputStream, scene::Scene) :: Float64\n\nRead a token from inputstream and check that its type is LiteralNumberToken  (i.e. a number) or IdentifierToken (i.e. a variable defined in scene),  throwing  GrammarError otherwise. Return the float64-parsed number or the identifier associated float64-parsed  number, respectively. Call internally read_token.\n\nSee also: InputStream, Scene, LiteralNumberToken,  IdentifierToken\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.expect_bool","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.expect_bool","text":" expect_bool(inputstream::InputStream, scene::Scene) :: Bool\n\nRead a token from inputstream and check that its type is KeywordToken  or IdentifierToken (i.e. a variable defined in scene),  throwing  GrammarError otherwise. Return the parsed bool or the identifier associated parsed bool, respectively. Call internally read_token.\n\nSee also: InputStream, Scene, KeywordToken,  IdentifierToken\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.expect_string","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.expect_string","text":" expect_string(inputstream::InputStream, scene::Scene) :: String\n\nRead a token from inputstream and check that its type is StringToken, throwing  GrammarError otherwise. Return the string associated with the readed StringToken. Call internally read_token.\n\nSee also: InputStream, Scene, StringToken, \n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.expect_identifier","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.expect_identifier","text":" expect_identifier(inputstream::InputStream) :: String\n\nRead a token from inputstream and check that it is an identifier. Return the name of the identifier.\n\nRead a token from inputstream and check that its type is IdentifierToken, throwing  GrammarError otherwise. Return the name of the identifier as a String. Call internally read_token.\n\nSee also: InputStream, Scene, IdentifierToken, \n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_vector","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_vector","text":"parse_vector(inputstream::InputStream, scene::Scene) :: Vec\n\nParse a vector from the given inputstream and return it. Call internally expect_number and expect_symbol.\n\nSee also: InputStream, Scene, Vec\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_color","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_color","text":" parse_color(inputstream::InputStream, scene::Scene) :: RGB{Float32}\n\nRead the color from the given inputstream and return it. Call internally 'expect_symbol' and 'expect_number'.\n\nSee also: 'InputStream', 'Scene'\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_pigment","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_pigment","text":" parse_pigment(inputstream::InputStream, scene::Scene) :: Pigment\n\nParse a pigment from the given inputstream and return it.\n\nCall internally the following parsing functions:\n\nexpect_keywords\nexpect_symbol\nparse_color\nexpect_number\nexpect_string\n\nCall internally the following functions and structs of the program:\n\nUniformPigment\nCheckeredPigment\nImagePigment\nload_image\n\nSee also: InputStream, Scene, Pigment\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_brdf","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_brdf","text":" parse_brdf(inputstream::InputStream, scene::Scene) :: BRDF\n\nParse a BRDF from the given inputstream and return it.\n\nCall internally the following parsing functions:\n\nexpect_keywords\nexpect_symbol\nparse_pigment\n\nCall internally the following functions and structs of the program:\n\nDiffuseBRDF\nSpecularBRDF\n\nSee also: InputStream, Scene, BRDF\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_material","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_material","text":" parse_material(inputstream::InputStream, scene::Scene) :: (String, Material)\n\nParse a Material from the given inputstream and return a tuple with the identifier name of the material and the material itself.\n\nCall internally the following parsing functions:\n\nexpect_identifier\nexpect_symbol\nparse_brdf\nparse_pigment\n\nCall internally the following functions and structs of the program:\n\nMaterial\n\nSee also: InputStream, Scene, Token, Material\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_transformation","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_transformation","text":" parse_transformation(inputstream::InputStream, scene::Scene) :: Transformation\n\nParse a Transformation from the given inputstream and return it.\n\nCall internally the following parsing functions:\n\nexpect_keywords\nexpect_symbol\nexpect_number\nparse_vector\nread_token\nunread_token\n\nCall internally the following functions and structs of the program:\n\ntranslation\nrotation_x\nrotation_y\nrotation_z\nscaling\n\nSee also: InputStream, Scene, Transformation\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_pointlight","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_pointlight","text":" parse_pointlight(inputstream::InputStream, scene::Scene) :: PointLight\n\nParse a PointLight from the given inputstream and return it.\n\nCall internally the following parsing functions:\n\nread_token\nunread_token\nexpect_number\nexpect_symbol\nparse_vector\nparse_color\n\nSee also: InputStream, Scene, PointLight\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_camera","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_camera","text":" parse_camera(inputstream::InputStream, scene::Scene) :: Camera\n\nParse a Camera from the given inputstream and return it.\n\nCall internally the following parsing functions:\n\nexpect_symbol\nexpect_keywords\nexpect_number\nparse_transformation\n\nCall internally the following functions and structs of the program:\n\nOrthogonalCamera\nPerspectiveCamera\n\nSee also: InputStream, Scene,  Camera\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.return_token_value","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.return_token_value","text":" return_token_value(\n      inputstream::InputStream, \n      scene::Scene\n      ) :: Union{Float64, Bool, String, Vec, RGB{Float32}, Pigment, BRDF}\n\nReturn the value of the token readed from inputstream. If the token is an IdentifierToken, return the value associated with that  identifier insdie the given scene. Throws GrammarError if an error occurs. Call internally the following parsing functions:\n\nread_token\nunread_token\nparse_vector\nparse_color\nparse_pigment\nparse_brdf\n\nSee also: Vec, Pigment, BRDF,  InputStream, Scene, GrammarError\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.assert","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.assert","text":" assert(inputstream::InputStream, scene::Scene)\n\nParse an assertion from the given inputstream and return it. Throws AssertionError if the assertion is false, nothing otherwise.\n\nCall internally the following parsing functions:\n\nexpect_symbol\nexpect_keywords\nexpect_number\nexpect_string\nreturn_token_value\n\nExamples\n\nassert(1, 1)             # Checks that 1==1\nassert(1, 2, \"<\")        # Checks that 1<2\nfloat var(1.0)           # Define var as a variable with value 1.0\nassert(var, 2, \"<=\")     # Checks that var<=2\n\nSee also: InputStream, Scene\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_scene","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_scene","text":" parse_scene(\n      inputstream::InputStream, \n      variables::Dict{String, Float64} = Dict()\n      ) :: Scene\n\nRead a scene description from the given inputstream and  return a Scene object. Throws GrammarError if an error occurs.\n\nCall internally the following parsing functions:\n\nread_token\nStopToken\nexpect_identifier\nexpect_symbol\nexpect_number\nparse_sphere\nparse_plane\nparse_camera\nparse_material\n\nCall internally the following functions and structs of the program:\n\nadd_shape!\nadd_light!\n\nSee also: InputStream, Scene\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Parsing-Shapes","page":"Interpreter for the Scene File","title":"Parsing Shapes","text":"","category":"section"},{"location":"interpreter/","page":"Interpreter for the Scene File","title":"Interpreter for the Scene File","text":"Raytracing.Interpreter.parse_sphere\nRaytracing.Interpreter.parse_plane","category":"page"},{"location":"interpreter/#Raytracing.Interpreter.parse_sphere","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_sphere","text":" parse_sphere(inputstream::InputStream, scene::Scene) :: Sphere\n\nParse a Sphere from the given inputstream and return it. Throws GrammarError if the specified Material does not exist.\n\nCall internally the following parsing functions:\n\nexpect_symbol\nexpect_identifier\nparse_transformation\n\nSee also: InputStream, Scene, Sphere Material\n\n\n\n\n\n","category":"function"},{"location":"interpreter/#Raytracing.Interpreter.parse_plane","page":"Interpreter for the Scene File","title":"Raytracing.Interpreter.parse_plane","text":" parse_plane(inputstream::InputStream, scene::Scene) :: Plane\n\nParse a Plane from the given inputstream and return it. Throws GrammarError if the specified Material does not exist.\n\nCall internally the following parsing functions:\n\nexpect_symbol\nexpect_identifier\nparse_transformation\n\nSee also: InputStream, Scene, Plane, Material\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/","page":"Reading and Writing PFM files","title":"Reading and Writing PFM files","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"readingwritingpfm/#Reading-and-Writing-PFM-file","page":"Reading and Writing PFM files","title":"Reading and Writing PFM file","text":"","category":"section"},{"location":"readingwritingpfm/","page":"Reading and Writing PFM files","title":"Reading and Writing PFM files","text":"Raytracing.InvalidPfmFileFormat\nRaytracing.valid_coordinates\nRaytracing.pixel_offset\nRaytracing.get_pixel\nRaytracing.set_pixel\nRaytracing.write(::IO, ::HDRimage)\nRaytracing.parse_img_size\nRaytracing.parse_endianness\nRaytracing.read_float\nRaytracing.read_line\nRaytracing.parse_command_line\nRaytracing.read(::IO, ::Type{HDRimage})\nRaytracing.load_image\nRaytracing.ldr2pfm","category":"page"},{"location":"readingwritingpfm/#Raytracing.InvalidPfmFileFormat","page":"Reading and Writing PFM files","title":"Raytracing.InvalidPfmFileFormat","text":"InvalidPfmFileFormat <: Exception (var::String)\n\nSelf-made exception raised by thne following function in case a reading operation of a PFM file fails:\n\nparse_img_size\nparse_endianness\nread_line\nread_float\nread(::IO, ::Type{HDRimage})\n\n\n\n\n\n","category":"type"},{"location":"readingwritingpfm/#Raytracing.valid_coordinates","page":"Reading and Writing PFM files","title":"Raytracing.valid_coordinates","text":"valid_coordinates(img::HDRimage, x::Int, y::Int) :: Bool\n\nReturn true if (x, y) are valid coordinates for the  2D matrix of the HDRimage, else return false.\n\nSee also: HDRimage\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/#Raytracing.pixel_offset","page":"Reading and Writing PFM files","title":"Raytracing.pixel_offset","text":"pixel_offset(img::HDRimage, x::Int, y::Int) :: Int64\n\nReturn the index in the 1D array of the specified pixel (x, y)  for the given HDRimage. Internally checks also if  (x, y)  are valid coordinates for img through the valid_coordinates function.\n\nSee also: valid_coordinates, HDRimage\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/#Raytracing.get_pixel","page":"Reading and Writing PFM files","title":"Raytracing.get_pixel","text":"get_pixel(img::HDRimage, x::Int, y::Int) :: RBG{Float32}\n\nReturn the RBG{Float32} color for the (x, y) pixel in the  given HDRimage, obtained through the pixel_offset function. The indexes for a HDRimage pixel matrix  with w width and h height follow this sketch:\n\n|  (0,0)    (0,1)    (0,2)   ...   (0,w-1)  |\n|  (1,0)    (1,1)    (1,2)   ...   (1,w-1)  |\n|   ...      ...      ...    ...     ...    |\n| (h-1,0)  (h-1,1)  (h-1,2)  ...  (h-1,w-1) |\n\nSee also: pixel_offset, HDRimage\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/#Raytracing.set_pixel","page":"Reading and Writing PFM files","title":"Raytracing.set_pixel","text":"set_pixel(img::HDRimage, x::Int, y::Int, c::RGB{Float32})\nset_pixel(img::HDRimage, x::Int, y::Int, c::RGB{T}) where {T}\n\nSet the new RGB color c for the (x, y) pixel in  the given HDRimage, acceded through the pixel_offset function. The indexes for a HDRimage pixel  matrix with w width and h height follow this sketch:\n\n|  (0,0)    (0,1)    (0,2)   ...   (0,w-1)  |\n|  (1,0)    (1,1)    (1,2)   ...   (1,w-1)  |\n|   ...      ...      ...    ...     ...    |\n| (h-1,0)  (h-1,1)  (h-1,2)  ...  (h-1,w-1) |\n\nIf c is of a type RGB{T} where T ≠ Float32, it's called the convert(RGB{Float32}, c) function, which raises an exception if the conversion is not possible.\n\nSee also: pixel_offset, HDRimage\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/#Base.write-Tuple{IO,HDRimage}","page":"Reading and Writing PFM files","title":"Base.write","text":"write(io::IO, img::HDRimage)\n\nWrite the given HDRimage image using the given IO stream as a PFM file. The endianness used for writing the file is Little Endian (-1.0).\n\nSee also: get_pixel, HDRimage\n\n\n\n\n\n","category":"method"},{"location":"readingwritingpfm/#Raytracing.parse_img_size","page":"Reading and Writing PFM files","title":"Raytracing.parse_img_size","text":"parse_img_size(line::String) :: (Int64, Int64)\n\nReturn the size (width, height) parsed from a given String, throwing  InvalidPfmFileFormat exception if encounters invalid values. It works inside the read(::IO, ::Type{HDRimage}) function.\n\nSee also: read(::IO, ::Type{HDRimage}),  InvalidPfmFileFormat\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/#Raytracing.parse_endianness","page":"Reading and Writing PFM files","title":"Raytracing.parse_endianness","text":"parse_endianness(ess::String) :: Float64\n\nReturn the endianness parsed from a given String, throwing  InvalidPfmFileFormat exception if encounters an invalid value. It works inside the read(::IO, ::Type{HDRimage}) function.\n\nSee also: read(::IO, ::Type{HDRimage}),  InvalidPfmFileFormat\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/#Raytracing.read_float","page":"Reading and Writing PFM files","title":"Raytracing.read_float","text":"read_float(io::IO, ess::Float64) :: Float32\n\nReturn a Float32, readed from the given IO stream io with the  (required) endianness ess; ess must be +1.0 (Big Endian) or  -1.0 (Little Endian). Controls also if there are enough bits in order to form a Float32,  otherwise throw InvalidPfmFileFormat. It works inside the read(::IO, ::Type{HDRimage}) function.\n\nSee also: read(::IO, ::Type{HDRimage}),  InvalidPfmFileFormat\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/#Raytracing.read_line","page":"Reading and Writing PFM files","title":"Raytracing.read_line","text":"read_line(io::IO) :: String\n\nReads a line from the file whose the given IO object io refers to.  Do understand when the file is ended and when a new line begins. Return the readed line as a String. It works inside the read(::IO, ::Type{HDRimage}) function.\n\nSee also: read(::IO, ::Type{HDRimage}),  InvalidPfmFileFormat\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/#Raytracing.parse_command_line","page":"Reading and Writing PFM files","title":"Raytracing.parse_command_line","text":"parse_command_line(args::Vector{String}) :: \n    (String, String, Float64, Float64)\n\nInterpret the command line when the main is executed,  and manage eventual argument errors.\n\nInput\n\nA args::Vector{String}) with length 2, 3 or 4.\n\nReturns\n\nA tuple (infile, outfile, a, γ) containing:\n\ninfile::String : first string (required), is the input file  name, which must be a PFM format.\noutfile::String : second string (required), is the output filename;  its format can be PNG or TIFF.\na::Float64 : third argument (optional), is the scale factor for  luminosity correction (default 0.18), passed to normalize_image!\nγ::Float64 : fourth argument (optional), is the gamma factor for  screen correction (default 1.0), passed to γ_correction!\n\nSee also : normalize_image!, γ_correction!\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/#Base.read-Tuple{IO,Type{HDRimage}}","page":"Reading and Writing PFM files","title":"Base.read","text":"read(io::IO, ::Type{HDRimage}) :: HDRimage\n\nRead a PFM image from a stream object io, and return a HDRimage  object containing the image. If an error occurs, raise a InvalidPfmFileFormat exception. Calls internally the following functions:\n\nparse_img_size\nparse_endianness\nread_line\nread_float\n\nSee also:  parse_img_size, parse_endianness,  read_line, read_float, InvalidPfmFileFormat, HDRimage\n\n\n\n\n\n","category":"method"},{"location":"readingwritingpfm/#Raytracing.load_image","page":"Reading and Writing PFM files","title":"Raytracing.load_image","text":"load_image(path::Union{String, IO}) :: HDRimage\n\nLoad an image from the specified path in an HDR image format.\n\nSee also: HDRimage\n\n\n\n\n\n","category":"function"},{"location":"readingwritingpfm/#Raytracing.ldr2pfm","page":"Reading and Writing PFM files","title":"Raytracing.ldr2pfm","text":"ldr2pfm(path::String, outfile::String)\n\nLoad an image from the specified path, convert it in a pfm file format and save it as outfile. It works through the load_image and the  write(::IO, ::HDRimage) function.\n\nSee also: HDRimage, load_image,   write(::IO, ::HDRimage)\n\n\n\n\n\n","category":"function"},{"location":"renderers/","page":"Renderers","title":"Renderers","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"renderers/#Renderers","page":"Renderers","title":"Renderers","text":"","category":"section"},{"location":"renderers/","page":"Renderers","title":"Renderers","text":"Raytracing.Renderer\nRaytracing.OnOffRenderer\nRaytracing.FlatRenderer\nRaytracing.PathTracer\nRaytracing.PointLightRenderer\nRaytracing.is_point_visible\nRaytracing.quick_ray_intersection","category":"page"},{"location":"renderers/#Raytracing.Renderer","page":"Renderers","title":"Raytracing.Renderer","text":"abstract type Renderer <: Function end\n\nAn abstract class implementing a solver of the rendering equation. The concrete sub-types of this abstract class are:\n\nOnOffRenderer\nFlatRenderer\nPathTracer\nPointLightRenderer\n\n\n\n\n\n","category":"type"},{"location":"renderers/#Raytracing.OnOffRenderer","page":"Renderers","title":"Raytracing.OnOffRenderer","text":"OnOffRenderer <: Renderer(\n    world::World = World()\n    background_color::RGB{Float32} = RGB{Float32}(0.0, 0.0, 0.0)\n    color::RGB{Float32} = RGB{Float32}(1.0, 1.0, 1.0)\n)\n\nA on/off renderer. If the ray intersecty anyone of the shape inside the given world, the returned color will be color; otherwise, if no shape is intersected, the returned color will be background_color.\n\nThis renderer is mostly useful for debugging purposes,  as it is really fast, but it produces boring images.\n\nSee also: Renderer, World\n\n\n\n\n\n","category":"type"},{"location":"renderers/#Raytracing.FlatRenderer","page":"Renderers","title":"Raytracing.FlatRenderer","text":"FlatRenderer <: Renderer(\n    world::World = World()\n    background_color::RGB{Float32} = RGB{Float32}(0.0, 0.0, 0.0)\n)\n\nA «flat» renderer. This renderer estimates the solution of the rendering equation by neglecting  any contribution of the light. It just uses the pigment of each surface to  determine how to compute the final radiance.\n\nSee also: Renderer, World\n\n\n\n\n\n","category":"type"},{"location":"renderers/#Raytracing.PathTracer","page":"Renderers","title":"Raytracing.PathTracer","text":"PathTracer <: Renderer(\n        world::World, \n        background_color::RGB{Float32} = RGB{Float32}(0.0, 0.0, 0.0),\n        pcg::PCG = PCG(),\n        num_of_rays::Int64 = 10,\n        max_depth::Int64 = 2,\n        russian_roulette_limit::Int64 = 3\n    )\n\nA simple path-tracing renderer.\n\nThe algorithm implemented here allows the caller to tune number  of rays thrown at each iteration, as well as the maximum depth.  It implements Russian roulette, so in principle it will take a  finite time to complete the calculation even if you set  max_depth to Inf.\n\nArguments\n\nworld::World : the world to be rendered\nbackground_color::RGB{Float32} : default background color  if the Ray doesn-t hit anything\npcg::PCG : PCG random number generator for evaluating integrals\nnum_of_rays::Int64 : number of Rays generated for each integral evaluation\nmax_depth::Int64 : maximal number recursive integrations; if a ray intersecting a surface has depth>max_depth, the returned color is RGB{Float32}(0,0,0)\nrussian_roulette_limit::Int64: depth at whitch the Russian  Roulette algorithm begins\n\nSee also: Renderer, Ray, World, PCG\n\n\n\n\n\n","category":"type"},{"location":"renderers/#Raytracing.PointLightRenderer","page":"Renderers","title":"Raytracing.PointLightRenderer","text":"PointLightRenderer <: Renderer (\n    world::World,\n    background_color::RGB{Float32} = RGB{Float32}(0., 0., 0.),\n    ambient_color::RGB{Float32} = RGB{Float32}(0.1, 0.1, 0.1)\n)\n\nA simple point-light tracing renderer.\n\nArguments\n\nworld::World : the world to be rendered\nbackground_color::RGB{Float32} : default background color  if the Ray doesn-t hit anything\nambient_color::RGB{Float32} : default ambient color \n\nSee also: Renderer, World\n\n\n\n\n\n","category":"type"},{"location":"renderers/#Raytracing.is_point_visible","page":"Renderers","title":"Raytracing.is_point_visible","text":"is_point_visible(\n        world::World, \n        point::Point, \n        observer_pos::Point\n        ) :: Bool\n\nReturn true if the straight line connecting observer_pos to point do not intersect any of the shapes of world between the two points, otherwise return false.\n\nSee also: World, Point\n\n\n\n\n\n","category":"function"},{"location":"renderers/#Raytracing.quick_ray_intersection","page":"Renderers","title":"Raytracing.quick_ray_intersection","text":"quick_ray_intersection(shape::Shape, ray::Ray) :: Bool\n\nQuickly determine whether the ray hits the shape or not.\n\nSee also: Shape, Ray\n\n\n\n\n\nquick_ray_intersection(sphere::Sphere, ray::Ray) :: Bool\n\nQuickly checks if the ray intersects the sphere or not.\n\nSee also: Sphere, Ray\n\n\n\n\n\nquick_ray_intersection(plane::Plane, ray::Ray) :: Bool\n\nQuickly checks if the ray intersects the plane or not.\n\nSee also: Plane, Ray\n\n\n\n\n\n","category":"function"},{"location":"base_structs/","page":"Base Structs","title":"Base Structs","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"base_structs/#Base-Structs-and-functions-of-the-program","page":"Base Structs","title":"Base Structs and functions of the program","text":"","category":"section"},{"location":"base_structs/","page":"Base Structs","title":"Base Structs","text":"Raytracing.HDRimage \nRaytracing.to_RGB \nRaytracing.get_matrix\nRaytracing.Parameters\nRaytracing.Point\nRaytracing.Vec\nRaytracing.Normal\nRaytracing.Transformation\nRaytracing.Ray\nRaytracing.at\nRaytracing.Camera\nRaytracing.fire_ray\nRaytracing.ImageTracer\nRaytracing.fire_all_rays!\nRaytracing.Pigment\nRaytracing.BRDF\nRaytracing.Material\nRaytracing.Shape\nRaytracing.Vec2d\nRaytracing.HitRecord\nRaytracing.PointLight\nRaytracing.World\nRaytracing.add_shape!\nRaytracing.add_light!\nRaytracing.PCG\nRaytracing.random\nRaytracing.create_onb_from_z\nRaytracing.scatter_ray\nRaytracing.are_close","category":"page"},{"location":"base_structs/#Raytracing.HDRimage","page":"Base Structs","title":"Raytracing.HDRimage","text":"HDRimage(\n    width::Int64\n    height::Int64\n    rgb_m::Array{RGB{Float32}} = fill(RGB(0.0, 0.0, 0.0), (width*height,))\n    )\n\nDefine a image in the format 2D  High-Dynamic-Range.\n\nArguments\n\nwidth::Float64 : width pixel number of the image\nheight::Float64 : height pixel number of the image\nrgb_m::Array{RGB{Float32}} : linearized color matrix;  the first element is the one in the bottom-left of the matrix,  then the line is read left-to-right and going to the upper row.\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.to_RGB","page":"Base Structs","title":"Raytracing.to_RGB","text":"to_RGB(r::Int64, g::Int64, b::Int64) :: RGB{Float32}\nto_RGB(r::Float64, g::Float64, b::Float64) :: RGB{Float32}\n\nReturn the RGB color with values inside the [0,1] interval.\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.get_matrix","page":"Base Structs","title":"Raytracing.get_matrix","text":"get_matrix(img::HDRimage) :: Matrix{RGB{Float32}}\n\nReturn the color matrix of the input img. The order of the pixel as they are stored in the HDRimage format is corrected in order to get the \"natural\" pixel matrix. \n\nSee also: HDRimage\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.Parameters","page":"Base Structs","title":"Raytracing.Parameters","text":"Parameters(\n    infile::String, \n    outfile::String,\n    a::Float64 = 0.18,\n    γ::Float64 = 1.0\n    )\n\nParameters passed from command line for the tone mapping.\n\nArguments\n\ninfile::String : input file name (must be a pfm)\noutfile::String : output file name (must be a png)\na::Float64 : parameter a for luminosity correction\nγ::Float64 : parameter γ for screen correction\n\nSee also: tone_mapping\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Point","page":"Base Structs","title":"Raytracing.Point","text":"Point(x::Float64, y::Float64, z::Float64)\n\nA point in 3D space.\n\nConstructors\n\nPoint() = new(0., 0. ,0.)\nPoint(x, y, z) = new(x, y, z)\nPoint(v::SVector{4, Float64}) = new(v[1], v[2], v[3])\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Vec","page":"Base Structs","title":"Raytracing.Vec","text":"Vec(x::Float64, y::Float64, z::Float64)\n\nA 3D Vector\n\nConstructors\n\nVec() = new(0., 0. ,0.)\nVec(x, y, z) = new(x, y, z)\nVec(P::Point) = new(P.x, P.y, P.z)\nVec(v::SVector{4, Float64}) = new(v[1], v[2], v[3])\nVec(N::Normal) = Vec(N.x, N.y, N.z)\n\nSee also: Normal\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Normal","page":"Base Structs","title":"Raytracing.Normal","text":"Normal(x::Float64, y::Float64, z::Float64)\n\nA normal vector in 3D space, you can give three components  and its struct normalize them.\n\nConstructors\n\nNormal(x,y,z) = new(x, y ,z)\nNormal(v::Vec) = new(v[1]/m, v[2]/m, v[3]/m)\nNormal(v::Vector{Float64}) = new(v[1]/m, v[2]/m, v[3]/m)\nNormal(v::SVector{4,Float64}) = new(v[1]/m, v[2]/m, v[3]/m)\n\n(m indicates the norm of the input vector)\n\nSee also: Vec\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Transformation","page":"Base Structs","title":"Raytracing.Transformation","text":"Transformation(M::SMatrix{4,4,Float64}, invM::SMatrix{4,4,Float64})\n\nContain two matrices 4x4 of Float64, one the inverse of the other. It's used to implement rotations, scaling and translations in 3D space  with homogenous formalism.\n\nNOTE: It does not check if invM is the inverse matrix of M, for computational efficiency purposes! In order to do that, looks at is_consistent(T::Transformation) function.\n\nConstructors\n\nTransformation(m, invm) = new(m, invm)\nTransformation() = new(            SMatrix{4,4}( Diagonal(ones(4)) ),             SMatrix{4,4}( Diagonal(ones(4)) )        )\n\nSee also: is_consistent\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Ray","page":"Base Structs","title":"Raytracing.Ray","text":"Ray(\n    origin::Point,\n    dir::Vec,\n    tmin::Float64 = 1e-5,\n    tmax::Float64 = Inf,\n    depth::Int64 = 0,\n    )\n\nA ray of light propagating in space.\n\nArguments\n\norigin::Point : origin of the ray\ndir::Vec : 3D direction along which this ray propagates\ntmin::Float64 : minimum distance travelled by the ray is this number times dir\ntmax::Float64 : maximum distance travelled by the ray is this number times dir\ndepth::Int64 : number of times this ray was reflected/refracted\n\nSee also: Point, Vec\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.at","page":"Base Structs","title":"Raytracing.at","text":"at(r::Ray, t::Float64) :: Point\n\nCompute the point along the ray's path at some distance from the origin.\n\nReturn a Point object representing the point in 3D space whose distance from the ray's origin is equal to t, measured in units of the length of Vec.dir.\n\nSee also: Ray, Point, Vec\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.Camera","page":"Base Structs","title":"Raytracing.Camera","text":"abstract type Camera end\n\nAn abstract type with the following concrete sub-types, defining different types of perspective projections:\n\nOrthogonalCamera\nPerspectiveCamera\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.fire_ray","page":"Base Structs","title":"Raytracing.fire_ray","text":"fire_ray(Ocam::OrthogonalCamera, u::Float64, v::Float64) :: Ray\nfire_ray(Pcam::PerspectiveCamera, u::Float64, v::Float64) :: Ray\nfire_ray(\n        ImTr::ImageTracer, \n        col::Int64, row::Int64, \n        u_px::Float64=0.5, v_px::Float64=0.5\n    ) :: Ray\n\nShoot one light Ray through the pixel (col, row) of ImTr.img image.  The parameters (col, row) are measured in a diffetent way compared to the HDRimage struct: here, the bottom left corner is placed at (0, 0). The following diagram shows the convenction for an image with dimensions (w,h):\n\n| (h,0)  (h,1)  (h,2)  ...  (h,w) |\n|  ...    ...    ...   ...   ...  |\n| (1,0)  (1,1)  (1,2)  ...  (1,w) |\n| (0,0)  (0,1)  (0,2)  ...  (0,w) |\n\nThe optional values u_px and v_px specify where the ray should cross the pixel; the convenction for their values are represented in the following  diagram as (u_px, v_px):\n\n(0, 1)                          (1, 1)\n    +------------------------------+\n    |                              |\n    |                              |\n    |                              |\n    +------------------------------+\n(0, 0)                          (1, 0)\n\nSee also: OrthogonalCamera, PerspectiveCamera, Ray, HDRimage, ImageTracer\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.ImageTracer","page":"Base Structs","title":"Raytracing.ImageTracer","text":"ImageTracer(\n    img::HDRimage,\n    cam::Camera,\n    samples_per_side::Int64 = 0,\n    pcg::PCG = PCG()\n    )\n\nImplement the \"screen\" of the observer.\n\nTrace an image by shooting light rays through each of its pixels.\n\nArguments\n\nimg::HDRimage : the image that will be rendered (required)\ncam::Camera : camera type of the observer (required)\nsamples_per_side::Int64 = 0 : if it is larger than zero, stratified sampling will  be applied to each pixel in the image, using the random number generator  pcg; if not, antialiasing will be ignored in fire_all_rays!\npcg::PCG = PCG() : PCG random number generator\n\nSee also: HDRimage,Camera, PCG, fire_ray, fire_all_rays!\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.fire_all_rays!","page":"Base Structs","title":"Raytracing.fire_all_rays!","text":"fire_all_rays!(\n        ImTr::ImageTracer, \n        func::Function, \n        callback::Union{Nothing, Function} = nothing,\n        callback_time_s::Float64 = 2.,\n        callback_kwargs::String\n        )\n\nShoot several light rays crossing each of the pixels in the ImTr.img image.\n\nFor each pixel in the HDRimage object fire one Ray, and pass it  to the function func, which must:\n\naccept a Ray as its only parameter \nreturn a RGB{Float32} color instance telling the color to  assign to that pixel in the image.\n\nIf callback is not nothing, it must be a function accepting at least two  parameters named col and row. This function is called periodically during the rendering, and the two mandatory  arguments are the row and column number of the last pixel that has been traced. \n\nPay Attention: Both the row and column are increased by one starting from zero: first the row and then the column.\n\nThe time between two consecutive calls to the callback can be tuned using the  parameter callback_time_s. Any keyword argument passed to fire_all_rays  is passed to the callback.\n\nSee also: Ray, HDRimage, ImageTracer\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.Pigment","page":"Base Structs","title":"Raytracing.Pigment","text":"abstract type Pigment end\n\nThis abstract class represents a pigment, i.e., a function that associates  a color with each point on a parametric surface (u,v). Call the function get_color to retrieve the color of the surface given a Vec2d object.\n\nThe concrete sub-types of this abstract class are:\n\nUniformPigment\nCheckeredPigment\nImagePigment\n\nSee also: Vec2d, get_color\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.BRDF","page":"Base Structs","title":"Raytracing.BRDF","text":"abstract type BRDF end\n\nAn abstract class representing a Bidirectional Reflectance Distribution Function. The concrete sub-types of this abstract class are:\n\nDiffuseBRDF\nSpecularBRDF\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Material","page":"Base Structs","title":"Raytracing.Material","text":"Material(\n    brdf::BRDF = DiffuseBRDF(),\n    emitted_radiance::Pigment = UniformPigment()\n)\n\nA struct representing a material.\n\nSee also: BRDF, DiffuseBRDF,  Pigment, UniformPigment \n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Shape","page":"Base Structs","title":"Raytracing.Shape","text":"abstract type Shape end\n\nAn abstract type with the following concrete sub-types, defining different types of shapes that can be created:\n\nSphere\nPlane\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Vec2d","page":"Base Structs","title":"Raytracing.Vec2d","text":"Vec2d(u::Float64, v::Float64)\n\nA 2D vector used to represent a point on a surface. The fields are named u and v to distinguish them from the usual 3D coordinates x, y, z.\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.HitRecord","page":"Base Structs","title":"Raytracing.HitRecord","text":"HitRecord(\n    world_point::Point,\n    normal::Normal,\n    surface_point::Vec2d,\n    t::Float64,\n    ray::Ray,\n    shape::Union{Shape, Nothing} = nothing\n    )\n\nA struct holding information about a ray-shape intersection.\n\nArguments\n\nworld_point::Point: world coordinates of the hit point\nnormal::Normal: orientation of the normal to the surface where the hit happened\nsurface_point::Vec2d : position of the hit point on the surface of the object\nt::Float64 : distance from the origin of the ray where the hit happened\nray::Ray : the ray that hit the surface\nshape::Union{Shape, Nothing}: shape on which the hit happened, or nothing if no intersection happened\n\nSee also: Point, Normal, Vec2d Ray, Shape\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.PointLight","page":"Base Structs","title":"Raytracing.PointLight","text":"PointLight(p::Point, c::Color, r::Float64 = 0.0)\n\nA point light (used by the point-light renderer). This class holds information about a point light (a Dirac's delta in the  rendering equation).\n\nArguments\n\nposition::Point : position of the point light in 3D space\ncolor::RGB{Float32} : color of the point light\nlinear_radius::Float64: if non-zero, this «linear radius» r is  used to compute the solid angle subtended by the light at a given  distance d through the formula (r  d)^2.\n\nSee also: Point, PointLightRenderer\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.World","page":"Base Structs","title":"Raytracing.World","text":"World(\n    shapes::Array{Shape} = Array{Shape,1}(),\n    point_lights::Array{PointLight} = Array{PointLight,1}()\n)\n\nA struct holding a list of shapes, which make a «world».\n\nYou can add shapes to a world using add_shape!, and call  ray_intersection to check whether a light ray intersects any of  the shapes in the world.\n\nFor the PointLightRenderer algorithm, you can also add point-lights source using add_light!, and world will keep a list of all of them.\n\nSee also: Shape, add_shape!, PointLight, add_light!, PointLightRenderer ray_intersection, Ray\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.add_shape!","page":"Base Structs","title":"Raytracing.add_shape!","text":"add_shape!(world::World, shape::Shape)\n\nAppend a new shape to the given world.\n\nSee also: Shape, World\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.add_light!","page":"Base Structs","title":"Raytracing.add_light!","text":"add_light!(world::World, pointlight::PointLight)\n\nAppend a new pointlight to the given world.\n\nSee also: PointLight, World\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.PCG","page":"Base Structs","title":"Raytracing.PCG","text":" PCG(state::UInt64 = UInt64(42), inc::UInt64 = UInt64(54))\n\nA mutable struct for the Permuted Congruential Generator (PCG)  which is a uniform pseudo-random number generator.\n\nParameters\n\nstate::UInt64 = UInt64(42) : initial state number\ninc::UInt64 = UInt64(54) : initial sequence number\n\nReferences\n\nMelissa E. O’Neill (2014), \"PCG: A Family of Simple Fast  Space-Efficient Statistically Good Algorithms  for Random Number Generation\"\n\nSee also: random(pcg::PCG, ::Type{UInt32}),  random(pcg::PCG, ::Type{Float64})\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.random","page":"Base Structs","title":"Raytracing.random","text":" random(pcg::PCG, ::Type{UInt32}) :: UInt32\n\nReturn a new random UInt32 number and advance PCG's internal state.\n\nThis function is based on the paper of Melissa E. O’Neill (2014),  where the Permuted Congruential Generator (PCG) family of random  number generators is defined and explained.\n\nReferences\n\nMelissa E. O’Neill (2014), \"PCG: A Family of Simple Fast  Space-Efficient Statistically Good Algorithms  for Random Number Generation\"\n\nSee also: random(pcg::PCG, ::Type{Float64}), PCG\n\n\n\n\n\n random(pcg::PCG, ::Type{Float64}) :: Float64\n\nReturns a Float64 random number inside [0,1] interval obtained  with a PCG Uniform Pseudo-random Number Generator.\n\nIt calls the random(pcg::PCG, ::Type{UInt32}) function, which returns a UInt32 random number, and divides it with typemax(UInt32).\n\nSee also: random(pcg::PCG, ::Type{UInt32}), PCG\n\n\n\n\n\n random(pcg::PCG) :: Float64\n\nReturns a Float64 random number inside [0,1] interval obtained  with a PCG Uniform Pseudo-random Number Generator.\n\nIt calls the random(pcg::PCG, ::Type{Float64}) function.\n\nSee also: random(pcg::PCG, ::Type{Float64}), random(pcg::PCG, ::Type{UInt32}), PCG\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.create_onb_from_z","page":"Base Structs","title":"Raytracing.create_onb_from_z","text":"create_onb_from_z(normal::Union{Vec, Normal}) :: (Normal, Normal, Normal)\n\nReturn an orthonormal base of 3 Normals with the z-axes  (i.e. the third Normal returned) parallel to the  input Vec/ Normal.\n\nThe implementation of this function is based on the paper of Duff et al. (2017), which improved the already efficient work made by Frisvad (2012).\n\nReferences\n\nDuff et al. (2017), \"Building an Orthonormal Basis,  Revisited\"\nFrisvad (2012), \"Building an Orthonormal Basis from a 3D  Unit Vector Without Normalization\"\n\nSee also: Vec, Normal\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.scatter_ray","page":"Base Structs","title":"Raytracing.scatter_ray","text":"scatter_ray(\n    ::Type{DiffuseBRDF},\n    pcg::PCG, \n    incoming_dir::Vec, \n    interaction_point::Point, \n    normal::Normal, \n    depth::Int64,\n    ) :: Ray\n\nReturn a Ray scattered by a material with a DiffuseBRDF.\n\nA DiffuseBRDF has a uniform BRDF, i.e.  f_r(mathbfx mathbfPsirightarrowmathbfTheta) = rho_d  pi; the importance sampling for the PathTracer algorithm use consequently the  following PDF:\n\np(omega) propto \n    f_r(mathbfx mathbfPsirightarrowmathbfTheta)  cos(vartheta)\n    = fracrho_dpi  cos(vartheta) \n    propto cos(vartheta)\n\n    Rightarrow quad\np(omega) = fraccos(vartheta)pi \n    quad Rightarrow quad\np(vartheta varphi) = fraccos(vartheta)  sin(vartheta) 2pi\n\nRightarrow quad\nbeginaligned\n    p(vartheta) = 2  cos(vartheta)  sin(vartheta) \r\n    p(varphi  vartheta) = frac12 pi\nendaligned\n\nSee also: DiffuseBRDF, Ray, Vec,  Point, Normal, PCG\n\n\n\n\n\nscatter_ray(\n    ::Type{SpecularBRDF},\n    pcg::PCG, \n    incoming_dir::Vec, \n    interaction_point::Point, \n    normal::Normal, \n    depth::Int64,\n    ) :: Ray\n\nReturn a Ray scattered by a material with a SpecularBRDF.\n\nA SpecularBRDF has a Dirac delta BRDF, i.e.:\n\nf_r(mathbfx mathbfPsi rightarrow mathbfTheta) \n    propto \nfracdelta(sin^2theta_r - sin^2theta)  \n    delta(psi_r pm pi - psi)costheta\n\nThe importance sampling for the PathTracer algorithm use consequently the  following PDF:\n\np(omega) propto \n    f_r(mathbfx mathbfPsirightarrowmathbfTheta)  cos(vartheta)\n    propto frac1cos(vartheta)  cos(vartheta) \n    propto cost\n\nSee also: SpecularBRDF, Ray, Vec,  Point, Normal, PCG\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.are_close","page":"Base Structs","title":"Raytracing.are_close","text":"are_close(x, y, ε=1e-10) :: Bool\n\nReturns true if the absolute difference between  x and y is smaller than ε.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/","page":"Range Tester Functions","title":"Range Tester Functions","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"range_testers/#The-render-function","page":"Range Tester Functions","title":"The render function","text":"","category":"section"},{"location":"range_testers/","page":"Range Tester Functions","title":"Range Tester Functions","text":"Raytracing.check_is_positive\nRaytracing.string2positive\nRaytracing.check_is_uint64\nRaytracing.string2int64\nRaytracing.check_is_even_uint64\nRaytracing.string2evenint64\nRaytracing.check_is_square\nRaytracing.string2rootint64\nRaytracing.check_is_color\nRaytracing.string2color\nRaytracing.check_is_vector\nRaytracing.string2vector\nRaytracing.check_is_declare_float\nRaytracing.declare_float2dict\nRaytracing.check_is_one_of\nRaytracing.string2stringoneof\nRaytracing.check_is_iterable\nRaytracing.string2iterable\nRaytracing.check_is_vec_variables\nRaytracing.string2vec_variables\nRaytracing.check_is_function\nRaytracing.string2function\nRaytracing.from_CLI_to_vecstring","category":"page"},{"location":"range_testers/#Raytracing.check_is_positive","page":"Range Tester Functions","title":"Raytracing.check_is_positive","text":" check_is_positive(string::String=\"\") :: Bool\n check_is_positive(number::Number) = check_is_positive(string(number))\n\nChecks if the input string is a number that can be parsed as  a positive Float64.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.string2positive","page":"Range Tester Functions","title":"Raytracing.string2positive","text":" string2positive(string::String) :: Float64\n string2positive(number::Number, uint::Bool=false) = \n      string2positive(string(number), uint)\n\nChecks if the input string is a number that can be parsed as  a positive Float64 with check_is_positive, and return it as a Float64.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.check_is_uint64","page":"Range Tester Functions","title":"Raytracing.check_is_uint64","text":" check_is_uint64(string::String=\"\") :: Bool\n check_is_uint64(number::Number) = check_is_uint64(string(number))\n\nChecks if the input string is a number that can be parsed as  a positive Int64.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.string2int64","page":"Range Tester Functions","title":"Raytracing.string2int64","text":" string2int64(string::String, uint::Bool=false) :: Union{Int64, UInt64}\n string2int64(number::Number, uint::Bool=false) = \n      string2int64(string(number), uint)\n\nChecks if the input string is a number that can be parsed as  a positive Int64 with check_is_uint64, and return it as a Int64 if uint==falseor as a UInt64 if uint==true.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.check_is_even_uint64","page":"Range Tester Functions","title":"Raytracing.check_is_even_uint64","text":" check_is_even_uint64(string::String=\"\") :: Bool\n check_is_even_uint64(number::Number) = check_is_even_uint64(string(number))\n\nChecks if the input string is a number that can be parsed as  an even positive Int64.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.string2evenint64","page":"Range Tester Functions","title":"Raytracing.string2evenint64","text":" string2evenint64(string::String, uint::Bool=false) :: Union{Int64, UInt64}\n string2evenint64(number::Number, uint::Bool=false) = string2evenint64(string(number), uint)\n\nChecks if the input string is a number that can be parsed as  an even positive Int64 with check_is_even_uint64, and return it as a Int64 if uint==falseor as a UInt64 if uint==true.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.check_is_square","page":"Range Tester Functions","title":"Raytracing.check_is_square","text":" check_is_square(string::String=\"\") :: Bool\n check_is_square(number::Number) = check_is_square(string(number))\n\nChecks if the input string is a number that can be parsed as  a squared positive Int64.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.string2rootint64","page":"Range Tester Functions","title":"Raytracing.string2rootint64","text":" string2rootint64(string::String) :: Int64\n string2rootint64(number::Number) = string2rootint64(string(number))\n\nChecks if the input string is a number that can be parsed as  a squared positive Int64 with check_is_square, and return the square root as a Int64.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.check_is_color","page":"Range Tester Functions","title":"Raytracing.check_is_color","text":" check_is_color(string::String=\"\") :: Bool\n\nChecks if the input string is a color written in RGB components as \"<R, G, B>\".\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.string2color","page":"Range Tester Functions","title":"Raytracing.string2color","text":" string2color(string::String=\"\") :: RGB{Float32}\n\nChecks if the input string is a color written in RGB components as \"<R, G, B>\" with check_is_color, and return it.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.check_is_vector","page":"Range Tester Functions","title":"Raytracing.check_is_vector","text":" check_is_vector(string::String=\"\") :: Bool\n\nChecks if the input string is a vector written in X,Y,Z components as \"[X, Y, Z]\".\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.string2vector","page":"Range Tester Functions","title":"Raytracing.string2vector","text":" string2vector(string::String=\"\") :: Union{Vec, Nothing}\n\nChecks if the input string is  a vector written in X,Y,Z components as \"[X, Y, Z]\" with check_is_vector, and return Vec(X,Y,Z).\n\nSee also: Vec\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.check_is_declare_float","page":"Range Tester Functions","title":"Raytracing.check_is_declare_float","text":" check_is_declare_float(string::String=\"\")\n\nChecks if the input string is a declaration of one (or more) floats in the form \"NAME:VALUE\" with check_is_declare_float. Examples:\n\n    --declare_float=name:1.0\n    --declare_float=name1:1.0,name2:2.0\n    --declare_float=\" name1 : 1.0 , name2: 2.0\"\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.declare_float2dict","page":"Range Tester Functions","title":"Raytracing.declare_float2dict","text":" declare_float2dict(string::String) :: Union{Dict{String, Float64}, Nothing}\n\nChecks if the input string is a declaration of one (or more) floats in the form \"NAME:VALUE\" with check_is_declare_float. Return a Dict{String, Float64} that associates each NAME (as keys) with its Float64 value, or nothing if string==\"\".\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.check_is_one_of","page":"Range Tester Functions","title":"Raytracing.check_is_one_of","text":"check_is_one_of(string::String, vec::Vector{String}) :: Bool\n\nChecks if the input string is inside one of the strings contained in vec.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.string2stringoneof","page":"Range Tester Functions","title":"Raytracing.string2stringoneof","text":"string2stringoneof(string::String, vec::Vector{String}) :: String\n\nChecks if the input string is inside one of the strings contained in vec with check_is_one_of, and return it.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.check_is_iterable","page":"Range Tester Functions","title":"Raytracing.check_is_iterable","text":" check_is_iterable(string::String, type::Union{Type, Nothing} = nothing) :: Bool\n check_is_iterable(object::T, type::Union{Type, Nothing} = nothing) where T<:Any \n      = check_is_iterable(string(object), type)\n\nChecks if the input string can be parsed in a iterable object, returning true if it is, otherwise false. If specified an input type, check also if all the elements contained  in object are of a type T such that T <: type. \n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.string2iterable","page":"Range Tester Functions","title":"Raytracing.string2iterable","text":" string2iterable(string::String=\"\") :: Vector{String}\n\nChecks if the input string is a vector of variable names written as \"[namevar1, namevar2, ...]\" with check_is_vec_variables,  and return a Vector{String} = [\"namevar1\", \"namevar2\", ...].\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.check_is_vec_variables","page":"Range Tester Functions","title":"Raytracing.check_is_vec_variables","text":" check_is_vec_variables(string::String=\"\") :: Bool\n\nChecks if the input string is a vector of variable names written as \"[namevar1, namevar2, ...]\".\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.string2vec_variables","page":"Range Tester Functions","title":"Raytracing.string2vec_variables","text":" string2vector(string::String=\"\") :: Union{Vector{String}, Nothing}\n\nChecks if the input string is a vector of variable names written as \"[namevar1, namevar2, ...]\" with check_is_vec_variables,  and return a Vector{String} = [\"namevar1\", \"namevar2\", ...].\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.check_is_function","page":"Range Tester Functions","title":"Raytracing.check_is_function","text":" check_is_function(string::String=\"\") :: Bool\n\nChecks if the input string is a function name defined in Raytracing.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.string2function","page":"Range Tester Functions","title":"Raytracing.string2function","text":" string2function(string::String=\"\") :: Function\n\nChecks if the input string is a function name defined in Raytracing with check_is_function, and return it.\n\n\n\n\n\n","category":"function"},{"location":"range_testers/#Raytracing.from_CLI_to_vecstring","page":"Range Tester Functions","title":"Raytracing.from_CLI_to_vecstring","text":" from_CLI_to_vecstring(string::String) :: Vector{String}\n\nParse a string as it would be from the Command Line, and return the  Vector{String} that contains all the commands parsed.\n\n\n\n\n\n","category":"function"},{"location":"render/","page":"The Render Function","title":"The Render Function","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"render/#The-render-function","page":"The Render Function","title":"The render function","text":"","category":"section"},{"location":"render/","page":"The Render Function","title":"The Render Function","text":"Raytracing.render\nRaytracing.parse_render_settings\nRaytracing.parse_onoff_settings\nRaytracing.parse_flat_settings\nRaytracing.parse_pathtracer_settings\nRaytracing.parse_pointlight_settings","category":"page"},{"location":"render/#Raytracing.render","page":"The Render Function","title":"Raytracing.render","text":"render(\n      scenefile::String,\n      renderer::Renderer = FlatRenderer(),\n \tcamera_type::Union{String, Nothing} = nothing,\n\tcamera_position::Union{Point, Vec, Nothing} = nothing, \n \tα::Float64 = 0., \n \twidth::Int64 = 640, \n \theight::Int64 = 480, \n      a::Float64 = 0.18,\n      γ::Float64 = 1.27,\n      lum::Union{Number, Nothing} = nothing,\n \tpfm_output::String = \"scene.pfm\", \n    \tpng_output::String = \"scene.png\",\n      samples_per_pixel::Int64 = 0,\n\tbool_print::Bool = true,\n\tbool_savepfm::Bool = true,\n      declare_float::Union{Dict{String,Float64}, Nothing} = nothing,\n      ONLY_FOR_TESTS::Bool = false,\n      )\n\nrender(x::(Pair{T1,T2} where {T1,T2})...) = \n     render( parse_render_settings(  Dict( pair for pair in [x...]) )... )\n\nRender the input scenefile with the specified options, and creates the following three files:\n\nthe PFM image (scene.pfm is the default name, if none is specified from the command line)\nthe LDR image (scene.png is the default name, if none is specified from the command line)\nthe JSON file (which has the same name of the LDR image and .json estention, so  scene.json is the default name, if none LDR image name is specified from the command line), that saves some datas about input commands, rendering time etc.\n\nArguments\n\nThe following input arguments refers to the first method presented in the signature; it's obviously very uncomfortable to use that method, so it's recommended to take  advantage of the second one, which allows to write the input values in a dictionary like syntax with arbitrary order and comfort. See the documentation of   parse_render_settings to learn how to use the keys:\n\nrenderer::Renderer = FlatRenderer() : renderer to be used in the rendering, with all the settings already setted (exception made for the world, that will be overridden and created here)\ncamera_type::String = \"per\" : set the perspective projection view:\ncamera_type==\"per\" -> set PerspectiveCamera  (default value)\ncamera_type==\"ort\"  -> set OrthogonalCamera\ncamera_position::Union{Point, Vec} = Point(-1.,0.,0.) : set the point of observation  in (X,Y,Z) coordinates, as aPointor aVec` input object.\nα::Float64 = 0. : angle of rotation IN RADIANTS, relative to the vertical (i.e. z) axis with a right-handed rule convention (clockwise rotation for entering (x,y,z)-axis  corresponds to a positive input rotation angle)\nwidth::Int64 = 640 and height::Int64 = 480 : pixel dimensions of the demo image; they must be both even positive integers.\na::Float64 = 0.18 : normalization scale factor for the tone mapping.\nγ::Float64 = 1.27 : gamma factor for the tone mapping.\nlum::Union{Number, Nothing} = nothing : average luminosity of the image; iIf not specified or equal to 0,  it's calculated through avg_lum\npfm_output::String = \"demo.pfm\" : name of the output pfm file\npng_output::String = \"demo.png\" : name of the output LDR file\nsamples_per_pixel::Int64 = 0 : number of rays per pixel to be used (antialiasing); it must be a perfect square positive integer (0, 1, 4, 9, ...) and if is set to 0 (default value) is choosen, no anti-aliasing occurs, and only one pixel-centered  ray is fired for each pixel.\nbool_print::Bool = true : specifies if the WIP messages of the demo function should be printed or not (useful option for render_animation)\nbool_savepfm::Bool = true : bool that specifies if the pfm file should be saved or not (useful option for render_animation)\ndeclare_float::Union{Dict{String,Float64}, Nothing} = nothing : an option (for the  command line in particularly) to manually override the values of the float variables in  the scene file; each overriden variable name (the key) is associated with its float value  (i.e. declare_float = Dict(\"var1\"=>0.1, \"var2\"=>2.5))\nONLY_FOR_TESTS::Bool = false : it's a bool variable conceived only to test the correct behaviour of the renderer for the input arguments; if set to true,  no rendering is made!\n\nSee also: Point, Vec, Renderer OnOffRenderer,  FlatRenderer, PathTracer, PointLightRenderer, parse_render_settings\n\n\n\n\n\n","category":"function"},{"location":"render/#Raytracing.parse_render_settings","page":"The Render Function","title":"Raytracing.parse_render_settings","text":"parse_render_settings(dict::Dict{String, T}) where {T}\n    :: (\n        String, Renderer, String, Vec, Float64, Int64, Int64, String,\n        String, Int64, Bool, Bool, Dict{String, Float64}, Bool,\n        )\n\nParse a Dict{String, T} where {T} for the render function.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (scenefile, renderer, camera_type, camera_position, α, width, height, pfm, png, samples_per_pixel, world_type, bool_print, bool_savepfm, declare_float, ONLY_FOR_TESTS)  containing the following variables (the corresponding keys are also showed):\n\nscenefile::String = dict[\"scenefile\"] : name of the scene file to be rendered; it must be written with the correct syntax, see the tutorial_basic_sintax.txt and the demo_world_B.txt files.\nrenderer::Renderer = haskey(dict, \"renderer\") ? dict[\"renderer\"] : dict[\"%COMMAND%\"] : it's the renderer to be used (with a default empy World that will be populated in the demo function); the possible keys are two, and must be used differently:\nthe dict[\"renderer\"] must contain the renderer itself (i.e. a Renderer object); if this key exists, it has the priority on the latter key\nthe dict[\"%COMMAND%\"] must contain a string that identifies the type of renderer to be used, i.e. one of the following strings:\n\"dict[\"%COMMAND%\"]=>onoff\" -> OnOffRenderer algorithm \n\"dict[\"%COMMAND%\"]=>\"flat\" -> FlatRenderer algorithm (default value)\n\"dict[\"%COMMAND%\"]=>\"pathtracing\" -> PathTracer algorithm \n\"dict[\"%COMMAND%\"]=>\"pointlight\" -> PointLightRenderer algorithm\nMoreover, in this second case, you can specify the options for the correspoding renderer through another dictionary associated with the kkey of the renderer name; that options will be parsed thanks to the corresponding functions. We shows in the next lines the key-value syntax described:\n\"onoff\"=>Dict{String, T} where {T} : parsed with parse_onoff_settings\n\"flat\"=>Dict{String, T} where {T} : parsed with parse_flat_settings\n\"pathtracer\"=>Dict{String, T} where {T} : parsed with parse_pathtracer_settings\n\"pointlight\"=>Dict{String, T} where {T} : parsed with parse_pointlight_settings\ncamera_type::String = dict[\"camera_type\"] : set the perspective projection view; it must be one of the following values, and this is checked with the  string2stringoneof function:\n\"per\" -> set PerspectiveCamera  (default value)\n\"ort\"  -> set OrthogonalCamera\ncamera_position::String = typeof(dict[\"camera_position\"]) ∈ [Vec, Point] ? dict[\"camera_position\"] : string2vector(dict[\"camera_position\"]) : \"[X, Y, Z]\" coordinates of the  choosen observation point of view; it can be specified in two ways:\nif typeof(dict[\"camera_position\"]) is a Vec or a Point, it's passed as-is\nelse, it must be a String written in the form \"[X, Y, Z]\" , and it's parsed through  string2vectorto aVec` object\nα::String = dict[\"alpha\"] : choosen angle of rotation IN RADIANTS respect to vertical (i.e. z)  axis with a right-handed rule convention (clockwise rotation for entering (x,y,z)-axis  corresponds to a positive input rotation angle)\nwidth::Int64 = string2evenint64(dict[\"width\"]) : number of pixels on the horizontal  axis to be rendered; it's converted through string2evenint64 to a even positive integer.\nheight::Int64 = string2evenint64(dict[\"height\"]) : number of pixels on the vertical axis to be rendered; it's converted through string2evenint64 to a even positive integer.\na::Float64 = string2positive(dict[\"normalization\"]) : scale factor (default = 0.18); it's converted  through string2positive to a positive floating point number.\nγ::Float64 = string2positive(dict[\"gamma\"]) : gamma factor (default = 1.0); it's converted  through string2positive to a positive floating point number.\nlum::Union{Number, Nothing} = string2positive(dict[\"avg_lum\"]) : average luminosity of the image; it's  converted through string2positive to a positive floating point number. If not specified or equal to 0,  it's calculated through avg_lum\npfm::String = dict[\"set_pfm_name\"] : output pfm filename (default \"scene.pfm\")\npng::String = dict[\"setpngname\"]: output LDR filename (default\"scene.png\"`)\nsamples_per_pixel::Int64  = dict[\"samples_per_pixel\"] : number of ray to be  generated for each pixel, implementing the anti-aliasing algorithm; it must be  a perfect integer square (0,1,4,9,...) and this is checked with the  string2rootint64 function; if 0 (default value) is choosen, no anti-aliasing  occurs, and only one pixel-centered ray is fired for each pixel.\nbool_print::Bool = dict[\"bool_print\"] : if true (default value), WIP message of  demo function are printed (otherwise no; it's useful for the demo_animation  function)\nbool_savepfm::Bool = dict[\"bool_savepfm\"] : if true (default value), demo  function saves the pfm file to disk (otherwise no; it's useful for the  demo_animation function)\ndeclare_float::Union{Dict{String, Float64}, Nothing} = declare_float2dict(dict[\"declare_float\"])  : an option for the command line to manually override the values of the float variables in  the scene file. The input dict[\"declare_float\"] must be a String written such as \"var1:0.1, var2 : 2.5\";  such a string is parsed through the declare_float2dict in a Dict{String, Float64}  where each overriden variable name (the key) is associated with its float value  (declare_float=>Dict(\"var1\"=>0.1, \"var2\"=>2.5))\nONLY_FOR_TESTS::Bool = dict[\"ONLY_FOR_TESTS\"] : it's a bool variable conceived only to test the correct behaviour of the renderer for the input arguments; if set to true,  no rendering is made!\n\nSee also:  render,  Renderer, Vec, string2evenint64, string2stringoneof,  string2positive, string2vector, string2rootint64, declare_float2dict\n\n\n\n\n\n","category":"function"},{"location":"render/#Raytracing.parse_onoff_settings","page":"The Render Function","title":"Raytracing.parse_onoff_settings","text":"parse_onoff_settings(dict::Dict{String, T}) where {T}\n    :: (World, RGB{Float32}, RGB{Float32})\n\nParse a Dict{String, T} where {T} for the initialisation of a OnOffRenderer.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (World(), background_color, color) containing the   following variables (the corresponding keys are also showed):\n\nWorld():: World : is the default constructor of the World class, which creates an empty world; it will be populated in the function that will use the renderer.\nbackground_color::RGB{Float32} = string2color(dict[\"background_color\"]) : set the  color returned by a light ray which does not hit any object in the scene; the default value is BLACK, i.e. RGB{Float32}(0.0, 0.0, 0.0). The input color value dict[\"background_color\"] must be a String written in RGB components as \"< R , G , B >\", and it's parsed with the string2color function.\ncolor::RGB{Float32} = string2color(dict[\"color\"]) : set the color returned by a  light ray which does hit any object in the scene; the default value is WHITE, i.e.  RGB{Float32}(1.0, 1.0, 1.0). The input color value dict[\"color\"] must be a String written in RGB components as \"< R , G , B >\", and it's parsed with the string2color function.\n\nSee also:  Renderer, OnOffRenderer,  World, string2color\n\n\n\n\n\n","category":"function"},{"location":"render/#Raytracing.parse_flat_settings","page":"The Render Function","title":"Raytracing.parse_flat_settings","text":"parse_flat_settings(dict::Dict{String, T}) where {T}\n    :: (World, RGB{Float32})\n\nParse a Dict{String, T} where {T} for the initialisation of a FlatRenderer.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (World(), background_color) containing the following variables  (the corresponding keys are also showed):\n\nWorld():: World : is the default constructor of the World class, which creates an empty world; it will be populated in the function that will use the renderer.\nbackground_color::RGB{Float32} = string2color(dict[\"background_color\"]) : set the  color returned by a light ray which does not hit any object in the scene; the default value is BLACK, i.e. RGB{Float32}(0.0, 0.0, 0.0). The input color value dict[\"background_color\"] must be a String written in RGB components as \"< R , G , B >\", and it's parsed with the string2color function.\n\nSee also:  Renderer, FlatRenderer,  World, string2color\n\n\n\n\n\n","category":"function"},{"location":"render/#Raytracing.parse_pathtracer_settings","page":"The Render Function","title":"Raytracing.parse_pathtracer_settings","text":"parse_pathtracer_settings(dict::Dict{String, T}) where {T}\n    :: (World(), RGB{Float32}, PCG, Int64, Int64, Int64)\n\nParse a Dict{String, T} where {T} for the initialisation of a PathTracer.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (World(), background_color, PCG(init_state, init_seq), num_of_rays,  max_depth, russian_roulette_limit, ONLY_FOR_TESTS) containing the following variables  (the corresponding keys are also showed):\n\nWorld():: World : is the default constructor of the World class, which creates an empty world; it will be populated in the function that will use the renderer.\nbackground_color::RGB{Float32} = string2color(dict[\"background_color\"]) : set the  color returned by a light ray which does not hit any object in the scene; the default value is BLACK, i.e. RGB{Float32}(0.0, 0.0, 0.0). The input color value dict[\"background_color\"] must be a String written in RGB components as \"< R , G , B >\", and it's parsed with the string2color function.\nPCG(init_state, init_seq)::PCG : a mutable struct of the Permuted Congruential  Generator (PCG), which is a uniform pseudo-random number generator; you can pass as  input two usigned integer that initialize the generator:\ninit_state::UInt64 = string2int64(dict[\"init_state\"], true) : set the initial state of the PCG; the input value dict[\"init_state\"] is parsed thanks to the string2int64 function.\ninit_seq::UInt64 = string2int64(dict[\"init_seq\"], true) : set the initial sequence of the PCG; the input value dict[\"init_seq\"] is parsed thanks to the string2int64 function.\nnum_of_rays::Int64 = string2int64(dict[\"num_of_rays\"]) : set the number of secondary  rays that will be fired from each surface point hitted by a light ray; the input value  dict[\"num_of_rays\"] is parsed thanks to the string2int64 function.\nmax_depth::Int64 = string2int64(dict[\"max_depth\"]) : set the maximum depth number that  the secondary rays are allowed to have; if that value is exceeded, no more secondary rays are generated in the hitten points, and the returned color is BLACK; the input value  dict[\"max_depth\"] is parsed thanks to the string2int64 function.\nrussian_roulette_limit::Int64 = string2int64(dict[\"russian_roulette_limit\"]) : set the  depth over which a secondary ray is created with the russian roulette algorithm; the input  value dict[\"russian_roulette_limit\"] is parsed thanks to the string2int64 function. \n\nSee also:  Renderer, PathTracer,  World, PCG, string2color, string2int64\n\n\n\n\n\n","category":"function"},{"location":"render/#Raytracing.parse_pointlight_settings","page":"The Render Function","title":"Raytracing.parse_pointlight_settings","text":"parse_pointlight_settings(dict::Dict{String, T}) where {T}\n    :: (World, RGB{Float32}, RGB{Float32})\n\nParse a Dict{String, T} where {T} for the initialisation of a PointLightRenderer.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (World(), background_color, color, ONLY_FOR_TESTS) containing the following variables  (the corresponding keys are also showed):\n\nWorld():: World : is the default constructor of the World class, which creates an empty world; it will be populated in the function that will use the renderer.\nbackground_color::RGB{Float32} = string2color(dict[\"background_color\"]) : set the  color returned by a light ray which does not hit any object in the scene; the default value is BLACK, i.e. RGB{Float32}(0.0, 0.0, 0.0). The input color value dict[\"background_color\"] must be a String written in RGB components as \"< R , G , B >\", and it's parsed with the string2color function.\nambient_color::RGB{Float32} = string2color(dict[\"ambient_color\"]) : set the minimum  color returned by a light ray which hits an object on a point, indipendently that is  or is not directy visible from any of the point-light sources in the scene; the default  value is BLACK, i.e. RGB{Float32}(0.0, 0.0, 0.0). The input color value dict[\"ambient_color\"] must be a String written in RGB components as \"< R , G , B >\", and it's parsed with the string2color function.\n\nSee also:  Renderer, PointLightRenderer,  World, string2color\n\n\n\n\n\n","category":"function"},{"location":"render/#The-render_animation-function","page":"The Render Function","title":"The render_animation function","text":"","category":"section"},{"location":"render/","page":"The Render Function","title":"The Render Function","text":"Raytracing.render_animation\nRaytracing.parse_render_animation_settings","category":"page"},{"location":"render/#Raytracing.render_animation","page":"The Render Function","title":"Raytracing.render_animation","text":"render_animation( \n\t\tfunc::Function,\n           vec_variables::Vector{String},\n           iterable::Any,\n           scenefile::String,\n           renderer_model::Renderer = FlatRenderer(),\n           camera_type::Union{String, Nothing} = nothing,\n           camera_position::Union{Point, Vec, Nothing} = nothing, \n           α::Float64 = 0., \n           width::Int64 = 640, \n           height::Int64 = 480, \n           a::Float64 = 0.18,\n           γ::Float64 = 1.27,\n           lum::Union{Number, Nothing} = nothing,\n           anim_output::String = \"scene_animation.mp4\", \n           samples_per_pixel::Int64 = 0,\n           bool_print::Bool = true,\n           declare_float::Union{Dict{String,Float64}, Nothing} = nothing,\n           ONLY_FOR_TESTS::Bool = false,     \n\t)\n\nrender_animation(x::(Pair{T1,T2} where {T1,T2})...) = \n\trender_animation( parse_render_animation_settings(  Dict( pair for pair in [x...]) )... )\n\nRender the input scenefile as an animation with the specified options, and creates the following three files:\n\nthe animation (scene_animation.mp4 is the default name, if none is specified from the command line)\nthe JSON file (which has the same name of the animation and .json estention, so  scene_animation.json is the default name), that saves some datas about input commands, rendering time etc.\n\nThis function works following this steps:\n\ncreates an hidden directory, called \".wip_animation\"; if it already exists, it will be destroyed and recreated.\ninside \".wpi_animation\", creates the png images of the rendered image (using the  render function with the specified projection, renderer and image  dims); each image correspons to a frame of the future animation\nthrough the ffmpeg software, the 360 png images are converted into the animation mp4 file, and saved in the main directory\nthe \".wpi_animation\" directory and all the png images inside it are destroyed\n\nArguments\n\nThe following input arguments refers to the first method presented in the signature; it's obviously very uncomfortable to use that method, so it's recommended to take  advantage of the second one, which allows to write the input values in a dictionary like syntax with arbitrary order and comfort. See the documentation of   parse_render_animation_settings to learn how to use the keys:\n\nfunc::Function : function that takes as input the frame number and returns the values  of the variables for that frame; it must have a method that takes only one input number,  and must return a tuple of length equals to the vec_variables one.\nvec_variables::Vector{String} : vector that contains the variable names (DEFINED IN SCENEFILE) that will be overridden from frame to frame; its length must equals the tuple length returned  by func.\niterable::Any : an iterable object, that defines the frame numbers and the total number of frames; its values will be given in input to func.\nrenderer::Renderer = FlatRenderer() : renderer to be used in the rendering, with all the settings already setted (exception made for the world, that will be overridden and created here)\ncamera_type::String = \"per\" : set the perspective projection view:\ncamera_type==\"per\" -> set PerspectiveCamera  (default value)\ncamera_type==\"ort\"  -> set OrthogonalCamera\ncamera_position::Union{Point, Vec} = Point(-1.,0.,0.) : set the point of observation  in (X,Y,Z) coordinates, as aPointor aVec` input object.\nα::Float64 = 0. : angle of rotation IN RADIANTS, relative to the vertical (i.e. z) axis with a right-handed rule convention (clockwise rotation for entering (x,y,z)-axis  corresponds to a positive input rotation angle)\nwidth::Int64 = 640 and height::Int64 = 480 : pixel dimensions of the demo image; they must be both even positive integers.\na::Float64 = 0.18 : normalization scale factor for the tone mapping.\nγ::Float64 = 1.27 : gamma factor for the tone mapping.\nlum::Union{Number, Nothing} = nothing : average luminosity of the image; iIf not specified or equal to 0,  it's calculated through avg_lum\nanim_output::String = \"scene_animation.mp4\" : name of the output animation file.\nsamples_per_pixel::Int64 = 0 : number of rays per pixel to be used (antialiasing); it must be a perfect square positive integer (0, 1, 4, 9, ...) and if is set to 0 (default value) is choosen, no anti-aliasing occurs, and only one pixel-centered  ray is fired for each pixel.\nbool_print::Bool = true : specifies if the WIP messages of the demo function should be printed or not.\ndeclare_float::Union{Dict{String,Float64}, Nothing} = nothing : an option (for the  command line in particularly) to manually override the values of the float variables in  the scene file; each overriden variable name (the key) is associated with its float value  (i.e. declare_float = Dict(\"var1\"=>0.1, \"var2\"=>2.5))\nONLY_FOR_TESTS::Bool = false : it's a bool variable conceived only to test the correct behaviour of the renderer for the input arguments; if set to true,  no rendering is made!\n\nSee also: Point, Vec, Renderer OnOffRenderer,  FlatRenderer, PathTracer, PointLightRenderer, parse_render_animation_settings, render\n\n\n\n\n\n","category":"function"},{"location":"render/#Raytracing.parse_render_animation_settings","page":"The Render Function","title":"Raytracing.parse_render_animation_settings","text":"parse_render_animation_settings(dict::Dict{String, T}) where {T}\n    :: (\n        Function, Vector{String}, Any,\n        String, Renderer, String, Vec, Float64, Int64, Int64, String,\n        Int64, Bool, Dict{String, Float64}, Bool,\n        )\n\nParse a Dict{String, T} where {T} for the render_animation function.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (func, vec_variables, iterable, scenefile, renderer, camera_type, camera_position,  α, width, height, anim, samples_per_pixel, bool_print, declare_float, ONLY_FOR_TESTS)  containing the following variables (the corresponding keys are also showed):\n\nscenefile::String = dict[\"scenefile\"] : name of the scene file to be rendered; it must be written with the correct syntax, see the tutorial_basic_sintax.txt and the demo_world_B.txt files.\nrenderer::Renderer = haskey(dict, \"renderer\") ? dict[\"renderer\"] : dict[\"%COMMAND%\"] : it's the renderer to be used (with a default empy World that will be populated in the demo function); the possible keys are two, and must be used differently:\nthe dict[\"renderer\"] must contain the renderer itself (i.e. a Renderer object); if this key exists, it has the priority on the latter key\nthe dict[\"%COMMAND%\"] must contain a string that identifies the type of renderer to be used, i.e. one of the following strings:\n\"dict[\"%COMMAND%\"]=>onoff\" -> OnOffRenderer algorithm \n\"dict[\"%COMMAND%\"]=>\"flat\" -> FlatRenderer algorithm (default value)\n\"dict[\"%COMMAND%\"]=>\"pathtracing\" -> PathTracer algorithm \n\"dict[\"%COMMAND%\"]=>\"pointlight\" -> PointLightRenderer algorithm\nMoreover, in this second case, you can specify the options for the correspoding renderer through another dictionary associated with the kkey of the renderer name; that options will be parsed thanks to the corresponding functions. We shows in the next lines the key-value syntax described:\n\"onoff\"=>Dict{String, T} where {T} : parsed with parse_onoff_settings\n\"flat\"=>Dict{String, T} where {T} : parsed with parse_flat_settings\n\"pathtracer\"=>Dict{String, T} where {T} : parsed with parse_pathtracer_settings\n\"pointlight\"=>Dict{String, T} where {T} : parsed with parse_pointlight_settings\ncamera_type::String = dict[\"camera_type\"] : set the perspective projection view; it must be one of the following values, and this is checked with the  string2stringoneof function:\n\"per\" -> set PerspectiveCamera  (default value)\n\"ort\"  -> set OrthogonalCamera\ncamera_position::String = typeof(dict[\"camera_position\"]) ∈ [Vec, Point] ? dict[\"camera_position\"] : string2vector(dict[\"camera_position\"]) : \"[X, Y, Z]\" coordinates of the  choosen observation point of view; it can be specified in two ways:\nif typeof(dict[\"camera_position\"]) is a Vec or a Point, it's passed as-is\nelse, it must be a String written in the form \"[X, Y, Z]\" , and it's parsed through  string2vectorto aVec` object\nα::String = dict[\"alpha\"] : choosen angle of rotation IN RADIANTS respect to vertical (i.e. z)  axis with a right-handed rule convention (clockwise rotation for entering (x,y,z)-axis  corresponds to a positive input rotation angle)\nwidth::Int64 = string2evenint64(dict[\"width\"]) : number of pixels on the horizontal  axis to be rendered; it's converted through string2evenint64 to a even positive integer.\nheight::Int64 = string2evenint64(dict[\"height\"]) : number of pixels on the vertical axis to be rendered; it's converted through string2evenint64 to a even positive integer.\na::Float64 = string2positive(dict[\"normalization\"]) : scale factor (default = 0.18); it's converted  through string2positive to a positive floating point number.\nγ::Float64 = string2positive(dict[\"gamma\"]) : gamma factor (default = 1.0); it's converted  through string2positive to a positive floating point number.\nlum::Union{Number, Nothing} = string2positive(dict[\"avg_lum\"]) : average luminosity of the image; it's  converted through string2positive to a positive floating point number. If not specified or equal to 0,  it's calculated through avg_lum\nanim::String = dict[\"set_anim_name\"] : output animation name (default \"animation.mp4\")\nsamples_per_pixel::Int64  = dict[\"samples_per_pixel\"] : number of ray to be  generated for each pixel, implementing the anti-aliasing algorithm; it must be  a perfect integer square (0,1,4,9,...) and this is checked with the  string2rootint64 function; if 0 (default value) is choosen, no anti-aliasing  occurs, and only one pixel-centered ray is fired for each pixel.\nbool_print::Bool = dict[\"bool_print\"] : if true (default value), WIP message of  demo function are printed (otherwise no; it's useful for the demo_animation  function)\ndeclare_float::Union{Dict{String, Float64}, Nothing} = declare_float2dict(dict[\"declare_float\"])  : an option for the command line to manually override the values of the float variables in  the scene file. The input dict[\"declare_float\"] must be a String written such as \"var1:0.1, var2 : 2.5\";  such a string is parsed through the declare_float2dict in a Dict{String, Float64}  where each overriden variable name (the key) is associated with its float value  (declare_float=>Dict(\"var1\"=>0.1, \"var2\"=>2.5))\nONLY_FOR_TESTS::Bool = dict[\"ONLY_FOR_TESTS\"] : it's a bool variable conceived only to test the correct behaviour of the renderer for the input arguments; if set to true,  no rendering is made!\n\nSee also:  render_animation,  Renderer, Vec, string2evenint64, string2stringoneof,  string2positive, string2vector, string2rootint64, declare_float2dict, string2iterable, string2vec_variables\n\n\n\n\n\n","category":"function"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"shapes/#Avaiable-shapes","page":"Avaiable Shapes","title":"Avaiable shapes","text":"","category":"section"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"ray_intersection(::Shape, ::Ray)\nray_intersection(::World, ::Ray)","category":"page"},{"location":"shapes/#Raytracing.ray_intersection-Tuple{Shape,Ray}","page":"Avaiable Shapes","title":"Raytracing.ray_intersection","text":"ray_intersection(shape::Shape, ray::Ray) :: Union{HitRecord, Nothing}\n\nCompute the intersection between a Ray and a Shape.\n\nSee also: Ray, Shape\n\n\n\n\n\n","category":"method"},{"location":"shapes/#Raytracing.ray_intersection-Tuple{World,Ray}","page":"Avaiable Shapes","title":"Raytracing.ray_intersection","text":"ray_intersection(world::World, ray::Ray) :: Union{HitRecord, Nothing}\n\nDetermine whether the ray intersects any of the objects of the given world. Return a HitRecord, or nothing if no intersection is found.\n\nSee also: Ray, World, HitRecord\n\n\n\n\n\n","category":"method"},{"location":"shapes/#Sphere","page":"Avaiable Shapes","title":"Sphere","text":"","category":"section"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"Raytracing.Sphere\nRaytracing.sphere_point_to_uv\nRaytracing.sphere_normal\nRaytracing.ray_intersection(::Sphere, ::Ray)","category":"page"},{"location":"shapes/#Raytracing.Sphere","page":"Avaiable Shapes","title":"Raytracing.Sphere","text":"Sphere <: Shape(\n    T::Transformation = Transformation(),\n    Material::Material = Material()\n)\n\nA 3D unit sphere, i.e. centered on the origin of the axes and with radius 1.0.\n\nArguments\n\nT::Transformation : transformation associated to the sphere.\nMaterial::Material : material that constitutes the sphere.\n\nSee also: Shape, Transformation, Material\n\n\n\n\n\n","category":"type"},{"location":"shapes/#Raytracing.sphere_point_to_uv","page":"Avaiable Shapes","title":"Raytracing.sphere_point_to_uv","text":"sphere_point_to_uv(point::Point) :: Vec2d\n\nConvert a 3D point P = (P_x P_y P_z) on the surface of the unit sphere into a 2D Vec2d using the following spherical coordinates:\n\nu = fracphi2pi = fracarctan (P_y  P_x)2pi \n    quad \nv = fracthetapi = fracarccos (P_z)pi\n\nSee also: Point, Vec2d, Sphere\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.sphere_normal","page":"Avaiable Shapes","title":"Raytracing.sphere_normal","text":"sphere_normal(point::Point, ray_dir::Vec) :: Normal\n\nCompute the Normal of a unit sphere.\n\nThe normal is computed for the given Point point = (P_x P_y P_z)  (with sqrtP_x^2 + P_y^2 + P_z^2=1) on the  surface of the sphere, and it is chosen so that it is always in the opposite direction with respect to the given Vec ray_dir.\n\nSee also: Point, Ray, Normal, Sphere\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.ray_intersection-Tuple{Sphere,Ray}","page":"Avaiable Shapes","title":"Raytracing.ray_intersection","text":"ray_intersection(sphere::Sphere, ray::Ray) :: Union{HitRecord, Nothing}\n\nCheck if the ray intersects the sphere. Return a HitRecord, or nothing if no intersection is found.\n\nSee also: Ray, Sphere, HitRecord\n\n\n\n\n\n","category":"method"},{"location":"shapes/#Plane","page":"Avaiable Shapes","title":"Plane","text":"","category":"section"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"Raytracing.Plane\nRaytracing.plane_point_to_uv\nRaytracing.plane_normal\nRaytracing.ray_intersection(::Plane, ::Ray)","category":"page"},{"location":"shapes/#Raytracing.Plane","page":"Avaiable Shapes","title":"Raytracing.Plane","text":"Plane <: Shape(\n    T::Transformation = Transformation(),\n    Material::Material = Material()\n)\n\nA 3D unit plane, i.e. the x-y plane (set of 3D points with z=0).\n\nArguments\n\nT::Transformation : transformation associated to the plane.\nMaterial::Material : material that constitutes the plane.\n\nSee also: Shape, Transformation, Material\n\n\n\n\n\n","category":"type"},{"location":"shapes/#Raytracing.plane_point_to_uv","page":"Avaiable Shapes","title":"Raytracing.plane_point_to_uv","text":"plane_point_to_uv(point::Point) :: Vec2d\n\nConvert a 3D point P = (P_x P_y P_z) on the surface of the unit plane into a 2D Vec2d using the following periodical coordinates:\n\nu = P_x - lfloor P_x rfloor\n    quad \nv = P_y - lfloor P_y rfloor\n\nwhere lfloor cdot rfloor indicates the rounding down approximation, in order to guarantee that u v in 0 1).\n\nSee also: Point, Vec2d, Plane\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.plane_normal","page":"Avaiable Shapes","title":"Raytracing.plane_normal","text":"plane_normal(point::Point, ray_dir::Vec) :: Normal\n\nCompute the Normal of a unit plane.\n\nThe normal is computed for the given point P = (P_x P_y 0) on the  surface of the plane, and it is chosen so that it is always in the opposite direction with respect to the given Vec ray_dir.\n\nSee also: Point, Ray, Normal, Plane\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.ray_intersection-Tuple{Plane,Ray}","page":"Avaiable Shapes","title":"Raytracing.ray_intersection","text":"ray_intersection(plane::Plane, ray::Ray) :: Union{HitRecord, Nothing}\n\nCheck if the ray intersects the plane. Return a HitRecord, or nothing if no intersection is found.\n\nSee also: Ray, Plane, HitRecord\n\n\n\n\n\n","category":"method"},{"location":"shapes/#Torus","page":"Avaiable Shapes","title":"Torus","text":"","category":"section"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"Raytracing.Torus\nRaytracing.torus_point_to_uv\nRaytracing.torus_normal\nRaytracing.ray_intersection(::Torus, ::Ray)","category":"page"},{"location":"shapes/#Raytracing.Torus","page":"Avaiable Shapes","title":"Raytracing.Torus","text":"Torus <: Shape(\n    T::Transformation = Transformation()\n    Material::Material = Material()\n    r::Float64 = 0.5\n    R::Float64 = 1.0\n)\n\nA 3D unit torus, a ring with circular section; has origin  in (0, 0, 0) and axis parallel to the y-axis.\n\nArguments\n\nT::Transformation: transformation associated to the torus.\nMaterial::Material : material that constitutes the torus.\nr::Float64 : radius of the circular section.\nR::Float64 : distance between the torus center and the section center.\n\n^ ̂y                __-__\n|                 /     \\ \n|---O------------(---o---)\n|                 \\__ __/\n|                    -\n      <--------R------><-r->\n\nSee also: Shape, Transformation, Material\n\n\n\n\n\n","category":"type"},{"location":"shapes/#Raytracing.torus_normal","page":"Avaiable Shapes","title":"Raytracing.torus_normal","text":"torus_normal(p::Point, ray_dir::Vec, R::Float64) -> Normal\n\nCompite the Normal of a torus\n\nThe normal is computed for Point (a point on the surface of the torus), and it is chosen so that it is always in the opposite direction with respect to ray_dir (Vec).\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.ray_intersection-Tuple{Torus,Ray}","page":"Avaiable Shapes","title":"Raytracing.ray_intersection","text":"ray_intersection(shape::Shape, ray::Ray) :: Union{HitRecord, Nothing}\n\nCompute the intersection between a Ray and a Shape.\n\nSee also: Ray, Shape\n\n\n\n\n\n","category":"method"},{"location":"shapes/#Cube","page":"Avaiable Shapes","title":"Cube","text":"","category":"section"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"Raytracing.Cube\nRaytracing.cube_point_to_uv\nRaytracing.cube_normal\nRaytracing.ray_intersection(::Cube, ::Ray)","category":"page"},{"location":"shapes/#Raytracing.Cube","page":"Avaiable Shapes","title":"Raytracing.Cube","text":"Cube <: Shape(\n    T::Transformation = Transformation(),\n    Material::Material = Material()\n)\n\nA 3D unit cube, i.e. an axis aligned cube with side 1 centered in the origin.\n\nArguments\n\nT::Transformation : transformation associated to the cube.\nMaterial::Material : material that constitutes the cube.\n\nSee also: Shape, Transformation, Material\n\n\n\n\n\n","category":"type"},{"location":"shapes/#Raytracing.cube_point_to_uv","page":"Avaiable Shapes","title":"Raytracing.cube_point_to_uv","text":"cube_point_to_uv(point::Point) :: Vec2d\n\nConvert a 3D point P = (P_x P_y P_z) on the surface of the unit cube into a 2D Vec2d using the following  coordinates:\n\nP_x = frac12 lor P_x = -frac12 \nquad Rightarrow quad \nu = P_y +  frac12      v = P_z +  frac12\n\nP_y = frac12 lor P_y = -frac12 \nquad Rightarrow quad \nu = P_x +  frac12      v = P_z +  frac12\n\nP_z = frac12 lor P_z = -frac12 \nquad Rightarrow quad \nu = P_x +  frac12      v = P_y +  frac12\n\nP_x neq frac12  -frac12 land\nP_y neq frac12  -frac12 land\nP_z neq frac12  -frac12 \nquad Rightarrow quad \nmathrmthrow Exception\n\nSee also: Point, Vec2d, Cube\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.cube_normal","page":"Avaiable Shapes","title":"Raytracing.cube_normal","text":"cube_normal(point::Point, ray_dir::Vec) :: Normal\n\nCompute the Normal of a unit cube.\n\nThe normal is computed for the given point on the  surface of the cube, and it is chosen so that it is always in the opposite direction with respect to the given Vec ray_dir.\n\nSee also: Point, Ray, Normal, Cube\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.ray_intersection-Tuple{Cube,Ray}","page":"Avaiable Shapes","title":"Raytracing.ray_intersection","text":"ray_intersection(cube::Cube, ray::Ray) :: Union{HitRecord, Nothing}\n\nCheck if the ray intersects the cube. Return a HitRecord, or nothing if no intersection is found.\n\nThe implementation is only a long boring list of if-else block statements, and may have to be optimized.\n\nSee also: Ray, Cube, HitRecord\n\n\n\n\n\n","category":"method"},{"location":"shapes/#Axis-Aligned-Bounding-Box","page":"Avaiable Shapes","title":"Axis-Aligned Bounding Box","text":"","category":"section"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"Raytracing.AABB\nRaytracing.ray_intersection(::AABB, ::Ray)","category":"page"},{"location":"shapes/#Raytracing.AABB","page":"Avaiable Shapes","title":"Raytracing.AABB","text":"AABB <: Shape(\n    vertexes::SVector{6, Float32}\n)\n\nAn Axis-Aligned Boundary Box.\n\nThis shape is not conceived to be rendered in the image, it has the only purpose to optimize the various ray_intersection functions.\n\nArguments\n\nvertexes::SVector{6, Float32} : the 6 coordinates of the exterior vertexes defining the AABB\n\nSee also: Shape, ray_intersection\n\n\n\n\n\n","category":"type"},{"location":"shapes/#Raytracing.ray_intersection-Tuple{AABB,Ray}","page":"Avaiable Shapes","title":"Raytracing.ray_intersection","text":"ray_intersection(AABB::AABB, ray::Ray) :: Bool\n\nCheck if the ray intersects the AABB. Return true if intersection occurs, false otherwise.\n\nSee also: Ray, AABB, HitRecord\n\n\n\n\n\n","category":"method"},{"location":"shapes/#Triangle","page":"Avaiable Shapes","title":"Triangle","text":"","category":"section"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"Raytracing.Triangle\nRaytracing.triangle_point_to_uv\nRaytracing.triangle_barycenter\nRaytracing.triangle_normal\nRaytracing.ray_intersection(::Triangle, ::Ray)","category":"page"},{"location":"shapes/#Raytracing.Triangle","page":"Avaiable Shapes","title":"Raytracing.Triangle","text":"Triangle <: Shape(\n    vertexes::SVector{3, Point} = \n        SVector{3, Point}(Point(√3/2, 0, 0), Point(0, 0.5, 0), Point(0, -0.5, 0)),\n    Material::Material = Material()\n)\n\nA 3D triangle.\n\nArguments\n\nvertexes::SVector{3, Point} : points associated to the triangle.\nMaterial::Material : material that constitutes the triangle.\n\nSee also: Shape, Material\n\n\n\n\n\n","category":"type"},{"location":"shapes/#Raytracing.triangle_point_to_uv","page":"Avaiable Shapes","title":"Raytracing.triangle_point_to_uv","text":"triangle_point_to_uv(triangle::Triangle, point::Point) :: Vec2d\n\nReturn the barycentic coordinates of the given point for the input \u001btriangle.\n\nIf the triangle is made of the vertexes (ABC) (memorized in this order), then the point P has coordinates (uv) = (beta gamma) such that:\n\n    P(beta gamma) = A + beta (B - A) + gamma (C-A)\n\nThe analitic resolution of this linear system is:\n\nbeginaligned\nbeta = frac\n            (P_x - A_x)(C_y - A_y) - (P_y - A_y)(C_x - A_x)\n        \n            (B_x - A_x)(C_y - A_y) - (B_y - A_y)(C_x - A_x)\n         \ngamma = frac\n            (P_x - A_x)(B_y - A_y) - (P_y - A_y)(B_x - A_x)\n        \n            (C_x - A_x)(B_y - A_y) - (C_y - A_y)(B_x - A_x)\n        \nendaligned\n\nNOTE: this function do not check if P is on the plane defined by (ABC),  neither if P is inside the triangle made of them!\n\nSee also: Triangle, Vec2d, Point\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.triangle_barycenter","page":"Avaiable Shapes","title":"Raytracing.triangle_barycenter","text":"triangle_barycenter(triangle::Triangle) :: Point\n\nReturn the barycenter of the given triangle.\n\nFor a triangle with vertexes (A B C), the barycenter is M:\n\n    M = fracA + B + C3\n\nSee also: Triangle, Point\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.triangle_normal","page":"Avaiable Shapes","title":"Raytracing.triangle_normal","text":"triangle_normal(triangle::Triangle, ray_dir::Vec) :: Normal\n\nCompute the Normal of a given triangle.\n\nThe normal for a triangle with vertexes (A B C) is computed as follows:\n\n    n = pm (B-A) times (C-A)\n\nwhere the sign is chosen so that it is always in the opposite direction with respect to the given ray_dir.\n\nSee also: Point, Ray, Normal, Triangle\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.ray_intersection-Tuple{Triangle,Ray}","page":"Avaiable Shapes","title":"Raytracing.ray_intersection","text":"ray_intersection(triangle::Triangle, ray::Ray) :: Union{HitRecord, Nothing}\n\nCheck if the ray intersects the triangle. Return a HitRecord, or nothing if no intersection is found.\n\nFor a triangle with vertexes (A B C) and a ray defined with the simple equation r(t) = O + t  vecd, the coordinates (uv) = (beta gamma) and the t value of intersection are obtained solving this linear system:\n\n\nbeginbmatrix\n    B_x-A_x  C_x-A_x  -d_x \n    B_y-A_y  C_y-A_y  -d_y \n    B_z-A_z  C_z-A_z  -d_z \nendbmatrix\n\nbeginbmatrix\nu \nv \nt\nendbmatrix\n= \nbeginbmatrix\nO_x - A_x\nO_z - A_z\nO_z - A_z\nendbmatrix\n\nSee also: Ray, Triangle, HitRecord\n\n\n\n\n\n","category":"method"},{"location":"brdfs_and_pigments/","page":"BRDFs and Pigments","title":"BRDFs and Pigments","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"brdfs_and_pigments/#BRDFs-and-Pigments","page":"BRDFs and Pigments","title":"BRDFs and Pigments","text":"","category":"section"},{"location":"brdfs_and_pigments/","page":"BRDFs and Pigments","title":"BRDFs and Pigments","text":"Raytracing.UniformPigment\nRaytracing.CheckeredPigment\nRaytracing.ImagePigment\nRaytracing.DiffuseBRDF\nRaytracing.SpecularBRDF\nRaytracing.get_color\nRaytracing.evaluate","category":"page"},{"location":"brdfs_and_pigments/#Raytracing.UniformPigment","page":"BRDFs and Pigments","title":"Raytracing.UniformPigment","text":"UniformPigment <: Pigment(\n    color::RGB{Float32} = RGB{Float32}(0.0, 0.0, 0.0)\n)\n\nA uniform pigment. This is the most boring pigment: a uniform hue over the whole surface.\n\nSee also: Pigment\n\n\n\n\n\n","category":"type"},{"location":"brdfs_and_pigments/#Raytracing.CheckeredPigment","page":"BRDFs and Pigments","title":"Raytracing.CheckeredPigment","text":"CheckeredPigment <: Pigment\n    color1::RGB{Float32} = RGB{Float32}(1.0, 1.0, 1.0),\n    color2::RGB{Float32} = RGB{Float32}(0.0, 0.0, 0.0),\n    num_steps::Int64 = 2\n)\n\nA checkered pigment. The number of rows/columns in the checkered pattern is tunable through the integer value num_steps, but you cannot have a different number of  repetitions along the u/v directions.\n\nSee also: Pigment\n\n\n\n\n\n","category":"type"},{"location":"brdfs_and_pigments/#Raytracing.ImagePigment","page":"BRDFs and Pigments","title":"Raytracing.ImagePigment","text":"ImagePigment <: Pigment(\n    image::HDRimage = HDRimage(3, 2, fill( BLACK, (6,) ) )\n)\n\nA textured pigment. The texture is given through a PFM image.\n\nSee also: Pigment, HDRimage\n\n\n\n\n\n","category":"type"},{"location":"brdfs_and_pigments/#Raytracing.DiffuseBRDF","page":"BRDFs and Pigments","title":"Raytracing.DiffuseBRDF","text":"DiffuseBRDF <: BRDF(\n    pigment::Pigment = UniformPigment(RGB{Float32}(1.0, 1.0, 1.0)),\n    reflectance::Float64 = 1.0\n)\n\nA class representing an ideal diffuse BRDF (also called «Lambertian»).\n\nSee also: Pigment, UniformPigment\n\n\n\n\n\n","category":"type"},{"location":"brdfs_and_pigments/#Raytracing.SpecularBRDF","page":"BRDFs and Pigments","title":"Raytracing.SpecularBRDF","text":"DiffuseBRDF <: BRDF(\n    pigment::Pigment = UniformPigment(RGB{Float32}(1.0, 1.0, 1.0)),\n    theresold_angle_rad::Float64 = π/180.\n)\n\nA class representing an ideal mirror BRDF.\n\nSee also: Pigment, UniformPigment\n\n\n\n\n\n","category":"type"},{"location":"brdfs_and_pigments/#Raytracing.get_color","page":"BRDFs and Pigments","title":"Raytracing.get_color","text":"get_color(p::UniformPigment, uv::Vec2d) :: RGB{Float32}\nget_color(p::CheckeredPigment, uv::Vec2d) :: RGB{Float32}\nget_color(p::ImagePigment, uv::Vec2d) :: RGB{Float32}\n\nReturn the RGB color of the pigment p at the specified (u,v) coordinates.\n\nSee also: Pigment, UniformPigment,  CheckeredPigment, ImagePigment, Vec2d\n\n\n\n\n\n","category":"function"},{"location":"brdfs_and_pigments/#Raytracing.evaluate","page":"BRDFs and Pigments","title":"Raytracing.evaluate","text":"evaluate(b::BRDF, n::Normal, in::Vec, out::Vec, uv::Vec2d) :: RGB{Float32}\nevaluate(b::DiffuseBRDF, n::Normal, in::Vec, out::Vec, uv::Vec2d) :: RGB{Float32}\nevaluate(b::SpecularBRDF, n::Normal, in::Vec, out::Vec, uv::Vec2d) :: RGB{Float32}\n\nReturn the RGB color with the specified BRDF b and spatial  configuation of durface normal n, incident ray direction in,  leaving ray direction out, (u,v) coordinates on surface.\n\nSee also: BRDF, DiffuseBRDF, SpecularBRDF Normal, Vec, Vec2d\n\n\n\n\n\n","category":"function"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"transformations/#Transformations","page":"Transformations","title":"Transformations","text":"","category":"section"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"Raytracing.rotation_x\nRaytracing.rotation_y\nRaytracing.rotation_z\nRaytracing.scaling\nRaytracing.translation\nRaytracing.inverse\nRaytracing.is_consistent","category":"page"},{"location":"transformations/#Raytracing.rotation_x","page":"Transformations","title":"Raytracing.rotation_x","text":"rotation_x(ϑ::Float64) :: Transformation\n\nEncoding a rotation around the x-axis of an angle ϑ in radiant. \n\nThe positive sign is given by the right-hand rule, therefore clockwise rotation for entering x-axis corresponds to a ϑ>0 rotation angle. \n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.rotation_y","page":"Transformations","title":"Raytracing.rotation_y","text":"rotation_y(ϑ::Float64) :: Transformation\n\nEncoding a rotation around the y-axis of an angle ϑ in radiant. \n\nThe positive sign is given by the right-hand rule, therefore clockwise rotation for entering y-axis corresponds to a ϑ>0 rotation angle. \n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.rotation_z","page":"Transformations","title":"Raytracing.rotation_z","text":"rotation_z(ϑ::Float64) :: Transformation\n\nEncoding a rotation around the z-axis of an angle ϑ in radiant. \n\nThe positive sign is given by the right-hand rule, therefore clockwise rotation for entering z-axis corresponds to a ϑ>0 rotation angle. \n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.scaling","page":"Transformations","title":"Raytracing.scaling","text":"scaling(v::Vec) :: Transformation\nscaling(x::Float64, y::Float64, z::Float64) = scaling(Vec(x,y,z))\n\nEncoding a scaling of the 3 spatial coordinates according to the vector v (negative values codify spatial reflections). \n\nEach component of  v must be different from zero.\n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.translation","page":"Transformations","title":"Raytracing.translation","text":"translation(v::Vec) :: Transformation\ntranslation(x::Float64, y::Float64, z::Float64) = translation(Vec(x,y,z))\n\nEncoding a rigid translation of the 3 spatial coordinates according to the vector v, which specifies the amount of shift to be applied along the three axes.\n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.inverse","page":"Transformations","title":"Raytracing.inverse","text":"inverse(T::Transformation) :: Transformation\n\nReturn the inverse affine transformation of T. This method is very cheap to call.\n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.is_consistent","page":"Transformations","title":"Raytracing.is_consistent","text":"is_consistent(T::Transformation) :: Bool\n\nCheck the internal consistency of the  input transformation,  returning a bool variable indicating whether T.M==T.invM. This method is useful when writing tests.\n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"cameras/","page":"Cameras","title":"Cameras","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"cameras/#Cameras","page":"Cameras","title":"Cameras","text":"","category":"section"},{"location":"cameras/","page":"Cameras","title":"Cameras","text":"Raytracing.OrthogonalCamera\nRaytracing.PerspectiveCamera","category":"page"},{"location":"cameras/#Raytracing.OrthogonalCamera","page":"Cameras","title":"Raytracing.OrthogonalCamera","text":"OrthogonalCamera <: Camera (\n    a::Float64 = 1.0,\n    T::Transformation = Transformation()\n)\n\nA camera implementing an orthogonal 3D → 2D projection. This class implements an observer seeing the world through an orthogonal projection.\n\nArguments\n\na::Float64 : aspect ratio, defines how larger than the height is the image.  For fullscreen images, you should probably set a to 16/9, as this is the  most used aspect ratio used in modern monitors.\nT::Transformation : transformation that defines the position of the observer.\n\nSee also: Transformation, Camera\n\n\n\n\n\n","category":"type"},{"location":"cameras/#Raytracing.PerspectiveCamera","page":"Cameras","title":"Raytracing.PerspectiveCamera","text":"PerspectiveCamera <: Camera (\n    d::Float64 = 1.0,\n    a::Float64 = 1.0,\n    T::Transformation = Transformation()\n    )\n\nA camera implementing a perspective 3D → 2D projection. This class implements an observer seeing the world through a perspective projection.\n\nArguments\n\nd::Float64: distance between the observer and the screen, it influences  the so-called «aperture» (the field-of-view angle along the horizontal direction).\na::Float64 : aspect ratio, defines how larger than the height is the image.  For fullscreen images, you should probably set a to 16/9, as this is the  most used aspect ratio used in modern monitors.\nT::Transformation : transformation that defines the position of the observer.\n\nSee also: Transformation, Camera\n\n\n\n\n\n","category":"type"},{"location":"tone_mapping/","page":"Tone Mapping","title":"Tone Mapping","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"tone_mapping/#Tone-Mapping","page":"Tone Mapping","title":"Tone Mapping","text":"","category":"section"},{"location":"tone_mapping/","page":"Tone Mapping","title":"Tone Mapping","text":"Raytracing.luminosity\nRaytracing.lum_max\nRaytracing.avg_lum\nRaytracing.clamp\nRaytracing.normalize_image!\nRaytracing.clamp_image!\nRaytracing.γ_correction!\nRaytracing.tone_mapping\nRaytracing.parse_tonemapping_settings","category":"page"},{"location":"tone_mapping/#Raytracing.luminosity","page":"Tone Mapping","title":"Raytracing.luminosity","text":"luminosity(c::RGB{T}) :: Float64\n\nReturn the best average luminosity of a color c = (R_i G_i B_i), through the Shirley & Morley proposal:\n\nl_i = fracmaxR_i G_i B_i  + minR_i G_i B_i 2\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.lum_max","page":"Tone Mapping","title":"Raytracing.lum_max","text":"lum_max(img::HDRimage) :: Float64\n\nReturn the maximum luminosity of the given img according to the luminosity function of a color.\n\nSee also: HDRimage, luminosity\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.avg_lum","page":"Tone Mapping","title":"Raytracing.avg_lum","text":"avg_lum(img::HDRimage, δ::Number=1e-10) :: Float64\n\nReturn the average luminosity of the img according to the luminosity function of a color. The δ parameter is used to prevent  numerical problems for  under-illuminated pixels.\n\nSee also: HDRimage, luminosity\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.clamp","page":"Tone Mapping","title":"Raytracing.clamp","text":"clamp(x::Number) :: Float64\n\nClamping function:\n\nx rightarrow x(x+1)\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.normalize_image!","page":"Tone Mapping","title":"Raytracing.normalize_image!","text":"normalize_image!(  \n        img::HDRimage, \n        a::Float64 = 0.18,\n        lum::Union{Number, Nothing} = nothing, \n        δ::Number = 1e-10\n        )\n\nNormalize the img colors through the following formula: \n\nforall  mathrmcolors  c =(R_i G_i B_i)  \nmathrmof  the  image   \r\n\nX_i rightarrow fracalangle l rangle X_i \n    quad  quad  \nforall X_i = R_i G_i B_i \n\nwhere langle l rangle is the average luminosity returned by the avg_lum function. \n\nSee also: HDRimage, avg_lum\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.clamp_image!","page":"Tone Mapping","title":"Raytracing.clamp_image!","text":"clamp_image!(img::HDRimage)\n\nAdjust the color levels of the brightest pixels in the img through the clamp function.\n\nSee also: HDRimage, clamp\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.γ_correction!","page":"Tone Mapping","title":"Raytracing.γ_correction!","text":"γ_correction!(img::HDRimage, γ::Float64=1.0, k::Float64=1.0)\n\nCorrects the image using the γ factor, assuming a potential dependence  between the input and output signals of a monitor/screen. \n\nAs third optional argument, you can pass the maximum value 'k' of the range  you want the RGB colors may have. The default value is 'k=1.0', so the range  RGB colors can span is '[0.0, 1.0]'\n\nSee also: HDRimage\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.tone_mapping","page":"Tone Mapping","title":"Raytracing.tone_mapping","text":"Tone-map the given input pfm file infile with luminosity normalisation a, gamma factor γ and average luminosity lum. Return a file with the input outfile name outfile and  of the specified LDR format, if possible.\n\nIn order to do the tone-mapping, this function relies on the following three function, called in the presented order:\n\nnormalize_image! : normalize the image colors\nclamp_image! : adjust the color levels of the brightest pixels\nγ_correction! : corrects the image using the γ factor\navg_lum : if not specified an average luminosity lum (or if it is =0), it is calculated through this function\n\nSee also: normalize_image!, clamp_image!,  γ_correction!, avg_lum\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.parse_tonemapping_settings","page":"Tone Mapping","title":"Raytracing.parse_tonemapping_settings","text":"parse_tonemapping_settings(dict::Dict{String, Any}) \n    :: (String, String, Float64, Float64, Bool)\n\nParse a Dict{String, T} where {T} for the tone_mapping function.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (pfm, png, a, γ, ONLY_FOR_TESTS) containing:\n\npfm::String = dict[\"infile\"] : input pfm filename (required)\npng::String = dict[\"outfile\"] : output LDR filename (required)\na::Float64 = string2positive(dict[\"normalization\"]) : scale factor (default = 0.18); it's converted  through string2positive to a positive floating point number.\nγ::Float64 = string2positive(dict[\"gamma\"]) : gamma factor (default = 1.0); it's converted  through string2positive to a positive floating point number.\nlum::Union{Number, Nothing} = string2positive(dict[\"avg_lum\"]) : average luminosity of the image; it's  converted through string2positive to a positive floating point number. If not specified or equal to 0,  it's calculated through avg_lum\nONLY_FOR_TESTS::Bool = dict[\"ONLY_FOR_TESTS\"] : it's a bool variable conceived only to test the correct behaviour of the renderer for the input arguments; if set to true,  no rendering is made!\n\nSee also:  tone_mapping, string2positive\n\n\n\n\n\n","category":"function"},{"location":"","page":"Introduction","title":"Introduction","text":"DocTestSetup = quote\r\n    using Raytracing\r\nend","category":"page"},{"location":"#Raytracer.jl-:-an-implementation-of-a-raytracing-program-in-Julia","page":"Introduction","title":"Raytracer.jl : an implementation of a raytracing program in Julia","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"This is the documentation of Raytracing.jl package, an implementation of a raytracing program written in Julia.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"This program has various features: it can generate simple fotorealistic images and animations, read and write High Dynamic Range images in PFM format and manipulate them throug a tone mapping algorithm.","category":"page"},{"location":"#Demo","page":"Introduction","title":"Demo","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Demo demo is the function that allows you to appreciate what type of image Raytracing.jl can create. It has two principal scenaries: one very simple used to better understand how every renderer implemented work and see an exemlpe of animation, the other, the other uses most of the shapes and \"material\" imlpemented. You can both use the function with the default parameters or choose them to directly see functioning of each variable.","category":"page"},{"location":"#Demo-animation","page":"Introduction","title":"Demo animation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Demo animation is a function showing a simple rotation of 360° around ten spheres (eight on the vertices of a cube and two on two surfaces). Uses ffmpeg software to generate a video (in .gif or .mp4 format).","category":"page"},{"location":"#Reading,-writing-and-tone-mapping-PFM-image","page":"Introduction","title":"Reading, writing and tone mapping PFM image","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"A useful features not only generating images but also as a mid step between the generation and the \"public\" visualization of an image is the possybility of saving a raw image and modify it. Following this pilosophy, after the generation two extension of the image are saved: .pfm and .png. If the luminosity or the color saturation doesn't correspond to your tastes or doesn't fit the color trait of your screen, you don't have to re-generate the whole image, but just need to find the best parameters to use in the tone mapping algorithm.","category":"page"},{"location":"#Documentation","page":"Introduction","title":"Documentation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The documentation was built using Documenter.jl.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Dates # hide\r\nprintln(\"Documentation built on $(now()) using Julia $(VERSION).\") # hide","category":"page"},{"location":"#Contents","page":"Introduction","title":"Contents","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"#Index","page":"Introduction","title":"Index","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"demo/","page":"Demo","title":"Demo","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"demo/#Demo","page":"Demo","title":"Demo","text":"","category":"section"},{"location":"demo/","page":"Demo","title":"Demo","text":"Raytracing.demo\nRaytracing.first_world\nRaytracing.second_world\nRaytracing.select_world\nRaytracing.parse_demo_settings","category":"page"},{"location":"demo/#Raytracing.demo","page":"Demo","title":"Raytracing.demo","text":"demo(\n     \trenderer::Renderer = FlatRenderer(),\n\tcamera_type::String = \"per\",\n\tcamera_position::Union{Point, Vec} = Point(-1.,0.,0.), \n \tα::Float64 = 0., \n \twidth::Int64 = 640, \n \theight::Int64 = 480, \n\ta::Float64=0.18, \n      γ::Float64=1.0, \n\tlum::Union{Number, Nothing} = nothing,\n \tpfm_output::String = \"demo.pfm\", \n    \tpng_output::String = \"demo.png\",\n\tsamples_per_pixel::Int64 = 0, \n\tworld_type::String = \"A\",\n\tbool_print::Bool = true,\n\tbool_savepfm::Bool = true,\n\tONLY_FOR_TESTS::Bool = false,\n      )\n\ndemo(x::(Pair{T1,T2} where {T1,T2})...) = \n\tdemo( parse_demo_settings(  Dict( pair for pair in [x...]) )... )\n\nCreates a demo image with the specified options. \n\nThere are two possible demo image \"world\" to be rendered, specified through the input string type.\n\nThe type==\"A\" demo image world consist in a set of 10 spheres of equal radius 0.1: 8 brown spheres are placed at the verteces of a cube of side 1.0, one green-purple  checked sphere is in the center of the lower cube face and another multi-colored sphere is in the center of the left cube face.\n\nThe type==\"B\" demo image world consists in a checked x-y plane, a blue opaque  sphere, a red reflecting sphere, and a green oblique reflecting plane, all inside a giant emetting sphere.\n\nThe creation of the demo image has the objective to check the correct behaviour of the rendering software, specifically the orientation upside-down and left-right.\n\nArguments\n\nThe following input arguments refers to the first method presented in the signature; it's obviously very uncomfortable to use that method, so it's recommended to take  advantage of the second one, which allows to write the input values in a dictionary like syntax with arbitrary order and comfort. See the documentation of   parse_demo_settings to learn how to use the keys:\n\nrenderer::Renderer = FlatRenderer() : renderer to be used in the rendering, with all the settings already setted (exception made for the world, that will be overridden and created here)\ncamera_type::String = \"per\" : set the perspective projection view:\ncamera_type==\"per\" -> set PerspectiveCamera  (default value)\ncamera_type==\"ort\"  -> set OrthogonalCamera\ncamera_position::Union{Point, Vec} = Point(-1.,0.,0.) : set the point of observation  in (X,Y,Z) coordinates, as aPointor aVec` input object.\nα::Float64 = 0. : angle of rotation IN RADIANTS, relative to the vertical (i.e. z) axis with a right-handed rule convention (clockwise rotation for entering (x,y,z)-axis  corresponds to a positive input rotation angle)\nwidth::Int64 = 640 and height::Int64 = 480 : pixel dimensions of the demo image; they must be both even positive integers.\na::Float64 = 0.18 : normalization scale factor for the tone mapping.\nγ::Float64 = 1.27 : gamma factor for the tone mapping.\nlum::Union{Number, Nothing} = nothing : average luminosity of the image; iIf not specified or equal to 0,  it's calculated through avg_lum\npfm_output::String = \"demo.pfm\" : name of the output pfm file\npng_output::String = \"demo.png\" : name of the output LDR file\nsamples_per_pixel::Int64 = 0 : number of rays per pixel to be used (antialiasing); it must be a perfect square positive integer (0, 1, 4, 9, ...) and if is set to 0 (default value) is choosen, no anti-aliasing occurs, and only one pixel-centered  ray is fired for each pixel.\nworld_type::String = \"A\" : specifies the type of world to be rendered (\"A\" or \"B\")\nbool_print::Bool = true : specifies if the WIP messages of the demo function should be printed or not (useful option for demo_animation)\nbool_savepfm::Bool = true : bool that specifies if the pfm file should be saved or not (useful option for demo_animation)\nONLY_FOR_TESTS::Bool = false : it's a bool variable conceived only to test the correct behaviour of the renderer for the input arguments; if set to true,  no rendering is made!\n\nSee also: Point, Vec, Renderer OnOffRenderer,  FlatRenderer, PathTracer, PointLightRenderer, demo_animation, parse_demo_settings\n\n\n\n\n\n","category":"function"},{"location":"demo/#Raytracing.first_world","page":"Demo","title":"Raytracing.first_world","text":"first_world() :: World\n\nRender the first world (identified with the string \"A\").\n\nThis world consists in a set of 10 spheres of equal radius 0.1: 8 brown spheres are placed at the verteces of a cube of side 1.0, one green-purple  checked sphere is in the center of the lower cube face and another multi-colored sphere is in the center of the left cube face.\n\nSee also: World, demo, demo_animation\n\n\n\n\n\n","category":"function"},{"location":"demo/#Raytracing.second_world","page":"Demo","title":"Raytracing.second_world","text":"second_world() :: World\n\nRender the second world (identified with the string \"B\").\n\nThis world consists in a checked x-y plane, a blue opaque  sphere, a red reflecting sphere, and a green oblique reflecting plane, all inside a giant emetting sphere.\n\nSee also: World, demo, demo_animation\n\n\n\n\n\n","category":"function"},{"location":"demo/#Raytracing.select_world","page":"Demo","title":"Raytracing.select_world","text":"select_world(type_world::String) ::Function\n\nSelect which demo world is used\n\n\n\n\n\n","category":"function"},{"location":"demo/#Raytracing.parse_demo_settings","page":"Demo","title":"Raytracing.parse_demo_settings","text":"parse_demo_settings(dict::Dict{String, T}) where {T}\n    :: (\n        Renderer, Point, Vec, Float64, Int64, Int64, String, String,\n        Int64, String, Bool, Bool, Bool,\n        )\n\nParse a Dict{String, T} where {T} for the demo function.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (renderer, camera_type, camera_position, α, width, height, pfm, png, samples_per_pixel, world_type, bool_print, bool_savepfm) containing the  following variables (the corresponding keys are also showed):\n\nrenderer::Renderer = haskey(dict, \"renderer\") ? dict[\"renderer\"] : dict[\"%COMMAND%\"] : it's the renderer to be used (with a default empy World that will be populated in the demo function); the possible keys are two, and must be used differently:\nthe dict[\"renderer\"] must contain the renderer itself (i.e. a Renderer object); if this key exists, it has the priority on the latter key\nthe dict[\"%COMMAND%\"] must contain a string that identifies the type of renderer to be used, i.e. one of the following strings:\n\"dict[\"%COMMAND%\"]=>onoff\" -> OnOffRenderer algorithm \n\"dict[\"%COMMAND%\"]=>\"flat\" -> FlatRenderer algorithm (default value)\n\"dict[\"%COMMAND%\"]=>\"pathtracing\" -> PathTracer algorithm \n\"dict[\"%COMMAND%\"]=>\"pointlight\" -> PointLightRenderer algorithm\nMoreover, in this second case, you can specify the options for the correspoding renderer through another dictionary associated with the kkey of the renderer name; that options will be parsed thanks to the corresponding functions. We shows in the next lines the key-value syntax described:\n\"onoff\"=>Dict{String, T} where {T} : parsed with parse_onoff_settings\n\"flat\"=>Dict{String, T} where {T} : parsed with parse_flat_settings\n\"pathtracer\"=>Dict{String, T} where {T} : parsed with parse_pathtracer_settings\n\"pointlight\"=>Dict{String, T} where {T} : parsed with parse_pointlight_settings\ncamera_type::String = dict[\"camera_type\"] : set the perspective projection view; it must be one of the following values, and this is checked with the  string2stringoneof function:\n\"per\" -> set PerspectiveCamera  (default value)\n\"ort\"  -> set OrthogonalCamera\ncamera_position::String = typeof(dict[\"camera_position\"]) ∈ [Vec, Point] ? dict[\"camera_position\"] : string2vector(dict[\"camera_position\"]) : \"[X, Y, Z]\" coordinates of the  choosen observation point of view; it can be specified in two ways:\nif typeof(dict[\"camera_position\"]) is a Vec or a Point, it's passed as-is\nelse, it must be a String written in the form \"[X, Y, Z]\" , and it's parsed through  string2vectorto aVec` object\nα::String = dict[\"alpha\"] : choosen angle of rotation IN RADIANTS respect to vertical (i.e. z)  axis with a right-handed rule convention (clockwise rotation for entering (x,y,z)-axis  corresponds to a positive input rotation angle)\nwidth::Int64 = string2evenint64(dict[\"width\"]) : number of pixels on the horizontal  axis to be rendered; it's converted through string2evenint64 to a even positive integer.\nheight::Int64 = string2evenint64(dict[\"height\"]) : number of pixels on the vertical axis to be rendered; it's converted through string2evenint64 to a even positive integer.\na::Float64 = string2positive(dict[\"normalization\"]) : scale factor (default = 0.18); it's converted  through string2positive to a positive floating point number.\nγ::Float64 = string2positive(dict[\"gamma\"]) : gamma factor (default = 1.0); it's converted  through string2positive to a positive floating point number.\nlum::Union{Number, Nothing} = string2positive(dict[\"avg_lum\"]) : average luminosity of the image; it's  converted through string2positive to a positive floating point number. If not specified or equal to 0,  it's calculated through avg_lum\npfm::String = dict[\"set_pfm_name\"] : output pfm filename (default \"demo.pfm\")\npng::String = dict[\"setpngname\"]: output LDR filename (default\"demo.png\"`)\nsamples_per_pixel::Int64  = dict[\"samples_per_pixel\"] : number of ray to be  generated for each pixel, implementing the anti-aliasing algorithm; it must be  a perfect integer square (0,1,4,9,...) and this is checked with the  string2rootint64 function; if 0 (default value) is choosen, no anti-aliasing  occurs, and only one pixel-centered ray is fired for each pixel.\nworld_type::String = dict[\"world_type\"] : type of the world to be rendered; it must be \"A\" or \"B\", and this is checked with the string2stringoneof function\nbool_print::Bool = dict[\"bool_print\"] : if true (default value), WIP message of  demo function are printed (otherwise no; it's useful for the demo_animation  function)\nbool_savepfm::Bool = dict[\"bool_savepfm\"] : if true (default value), demo  function saves the pfm file to disk (otherwise no; it's useful for the  demo_animation function)\nONLY_FOR_TESTS::Bool = dict[\"ONLY_FOR_TESTS\"] : it's a bool variable conceived only to test the correct behaviour of the renderer for the input arguments; if set to true,  no rendering is made!\n\nSee also:  demo, demo_animation, Renderer, Vec, string2evenint64, string2stringoneof,  string2positive, string2vector, string2rootint64\n\n\n\n\n\n","category":"function"},{"location":"demo/#Demo-Animation","page":"Demo","title":"Demo Animation","text":"","category":"section"},{"location":"demo/","page":"Demo","title":"Demo","text":"Raytracing.demo_animation\nRaytracing.parse_demoanimation_settings","category":"page"},{"location":"demo/#Raytracing.demo_animation","page":"Demo","title":"Raytracing.demo_animation","text":"demo_animation( \n\t\trenderer::Renderer = FlatRenderer(),\n\t\tcamera_type::String = \"per\",\n    \t\twidth::Int64 = 200, \n    \t\theight::Int64 = 150,\n   \t\tanim_output::String = \"demo-animation.mp4\",\n\t\tsamples_per_pixel::Int64 = 0,\n\t\tworld_type::String = \"A\", \n\t\tONLY_FOR_TESTS::Bool = false,\n\t)\n\ndemo_animation(x::(Pair{T1,T2} where {T1,T2})...) = \n\tdemo_animation( parse_demoanimation_settings(  Dict( pair for pair in [x...]) )... )\n\nCreates an animation of the demo image with the specified options. It's necessary to have istalled the ffmpeg software to run this function.\n\nThis function works following this steps:\n\ncreates an hidden directory, called \".wip_animation\"; if it already exists, it will be destroyed and recreated.\ninside \".wpi_animation\", creates 360 png images of the demo image (using the  demo function with the specified projection, renderer and image  dims); each image correspons to a frame of the future animation\nthrough the ffmpeg software, the 360 png images are converted into the animation mp4 file, and saved in the main directory\nthe \".wpi_animation\" directory and all the png images inside it are destroyed\n\nArguments\n\nThe following input arguments refers to the first method presented in the signature; it's obviously very uncomfortable to use that method, so it's recommended to take  advantage of the second one, which allows to write the input values in a dictionary like syntax with arbitrary order and comfort. See the documentation of   parse_demoanimation_settings to learn how to use the keys:\n\nrenderer::Renderer = FlatRenderer() : renderer to be used in the rendering, with all the settings already setted (exception made for the world, that will be overridden and created here)\ncamera_type::String = \"per\" : set the perspective projection view:\ncamera_type==\"per\" -> set PerspectiveCamera  (default value)\ncamera_type==\"ort\"  -> set OrthogonalCamera\ncamera_position::Union{Point, Vec} = Point(-1.,0.,0.) : set the point of observation  in (X,Y,Z) coordinates, as aPointor aVec` input object.\nwidth::Int64 = 640 and height::Int64 = 480 : pixel dimensions of the demo image; they must be both even positive integers.\na::Float64 = 0.18 : normalization scale factor for the tone mapping.\nγ::Float64 = 1.27 : gamma factor for the tone mapping.\nlum::Union{Number, Nothing} = nothing : average luminosity of the image; iIf not specified or equal to 0,  it's calculated through avg_lum\nanim_output::String = \"demo-animation.mp4\" : name of the output animation file\nsamples_per_pixel::Int64 = 0 : number of rays per pixel to be used (antialiasing); it must be a perfect square positive integer (0, 1, 4, 9, ...) and if is set to 0 (default value) is choosen, no anti-aliasing occurs, and only one pixel-centered  ray is fired for each pixel.\nworld_type::String = \"A\" : specifies the type of world to be rendered (\"A\" or \"B\")\nONLY_FOR_TESTS::Bool = false : it's a bool variable conceived only to test the correct behaviour of the renderer for the input arguments; if set to true,  no rendering is made!\n\nSee also: Point, Vec, Renderer OnOffRenderer,  FlatRenderer, PathTracer, PointLightRenderer, demo, parse_demoanimation_settings\n\n\n\n\n\n","category":"function"},{"location":"demo/#Raytracing.parse_demoanimation_settings","page":"Demo","title":"Raytracing.parse_demoanimation_settings","text":"parse_demoanimation_settings(dict::Dict{String, T}) where {T}\n    :: (\n        Renderer, String, Vec, Int64, Int64, String,\n        Int64, String, Bool,\n        )\n\nParse a Dict{String, T} where {T} for the demo_animation function.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (renderer, camera_type, camera_position, width, height, anim,  samples_per_pixel, world_type) containing the following variables  (the corresponding keys are also showed):\n\nrenderer::Renderer = haskey(dict, \"renderer\") ? dict[\"renderer\"] : dict[\"%COMMAND%\"] : it's the renderer to be used (with a default empy World that will be populated in the demo function); the possible keys are two, and must be used differently:\nthe dict[\"renderer\"] must contain the renderer itself (i.e. a Renderer object); if this key exists, it has the priority on the latter key\nthe dict[\"%COMMAND%\"] must contain a string that identifies the type of renderer to be used, i.e. one of the following strings:\n\"dict[\"%COMMAND%\"]=>onoff\" -> OnOffRenderer algorithm \n\"dict[\"%COMMAND%\"]=>\"flat\" -> FlatRenderer algorithm (default value)\n\"dict[\"%COMMAND%\"]=>\"pathtracing\" -> PathTracer algorithm \n\"dict[\"%COMMAND%\"]=>\"pointlight\" -> PointLightRenderer algorithm\nMoreover, in this second case, you can specify the options for the correspoding renderer through another dictionary associated with the kkey of the renderer name; that options will be parsed thanks to the corresponding functions. We shows in the next lines the key-value syntax described:\n\"onoff\"=>Dict{String, T} where {T} : parsed with parse_onoff_settings\n\"flat\"=>Dict{String, T} where {T} : parsed with parse_flat_settings\n\"pathtracer\"=>Dict{String, T} where {T} : parsed with parse_pathtracer_settings\n\"pointlight\"=>Dict{String, T} where {T} : parsed with parse_pointlight_settings\ncamera_type::String = dict[\"camera_type\"] : set the perspective projection view; it must be one of the following values, and this is checked with the  string2stringoneof function:\n\"per\" -> set PerspectiveCamera  (default value)\n\"ort\"  -> set OrthogonalCamera\ncamera_position::String = typeof(dict[\"camera_position\"]) ∈ [Vec, Point] ? dict[\"camera_position\"] : string2vector(dict[\"camera_position\"]) : \"[X, Y, Z]\" coordinates of the  choosen observation point of view; it can be specified in two ways:\nif typeof(dict[\"camera_position\"]) is a Vec or a Point, it's passed as-is\nelse, it must be a String written in the form \"[X, Y, Z]\" , and it's parsed through  string2vectorto aVec` object\nwidth::Int64 = string2evenint64(dict[\"width\"]) : number of pixels on the horizontal  axis to be rendered; it's converted through string2evenint64 to a even positive integer.\nheight::Int64 = string2evenint64(dict[\"height\"]) : number of pixels on the vertical axis to be rendered; it's converted through string2evenint64 to a even positive integer.\na::Float64 = string2positive(dict[\"normalization\"]) : scale factor (default = 0.18); it's converted  through string2positive to a positive floating point number.\nγ::Float64 = string2positive(dict[\"gamma\"]) : gamma factor (default = 1.0); it's converted  through string2positive to a positive floating point number.\nlum::Union{Number, Nothing} = string2positive(dict[\"avg_lum\"]) : average luminosity of the image; it's  converted through string2positive to a positive floating point number. If not specified or equal to 0,  it's calculated through avg_lum\nanim::String = dict[\"set_anim_name\"] : output animation filename (default  \"demo_animation.mp4\")\nsamples_per_pixel::Int64  = dict[\"samples_per_pixel\"] : number of ray to be  generated for each pixel, implementing the anti-aliasing algorithm; it must be  a perfect integer square (0,1,4,9,...) and this is checked with the  string2rootint64 function; if 0 (default value) is choosen, no anti-aliasing  occurs, and only one pixel-centered ray is fired for each pixel.\nworld_type::String = dict[\"world_type\"] : type of the world to be rendered; it must be \"A\" or \"B\", and this is checked with the string2stringoneof function\nONLY_FOR_TESTS::Bool = dict[\"ONLY_FOR_TESTS\"] : it's a bool variable conceived only to test the correct behaviour of the renderer for the input arguments; if set to true,  no rendering is made!\n\nSee also:  demo, demo_animation, Renderer, Vec, string2evenint64, string2stringoneof,  string2positive, string2vector, string2rootint64\n\n\n\n\n\n","category":"function"}]
}
