var documenterSearchIndex = {"docs":
[{"location":"renderers/","page":"Renderers","title":"Renderers","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"renderers/#Renderers","page":"Renderers","title":"Renderers","text":"","category":"section"},{"location":"renderers/","page":"Renderers","title":"Renderers","text":"Renderer\nOnOffRenderer\nFlatRenderer\nPathTracer\nPointLightRenderer\nis_point_visible\nquick_ray_intersection","category":"page"},{"location":"renderers/#Raytracing.Renderer","page":"Renderers","title":"Raytracing.Renderer","text":"abstract type Renderer <: Function end\n\nAn abstract class implementing a solver of the rendering equation. The concrete sub-types of this abstract class are:\n\nOnOffRenderer\nFlatRenderer\nPathTracer\nPointLightRenderer\n\n\n\n\n\n","category":"type"},{"location":"renderers/#Raytracing.OnOffRenderer","page":"Renderers","title":"Raytracing.OnOffRenderer","text":"OnOffRenderer <: Renderer(\n    world::World = World()\n    background_color::RGB{Float32} = RGB{Float32}(0.0, 0.0, 0.0)\n    color::RGB{Float32} = RGB{Float32}(1.0, 1.0, 1.0)\n)\n\nA on/off renderer. If the ray intersecty anyone of the shape inside the given world, the returned color will be color; otherwise, if no shape is intersected, the returned color will be background_color.\n\nThis renderer is mostly useful for debugging purposes,  as it is really fast, but it produces boring images.\n\nSee also: Renderer, World\n\n\n\n\n\n","category":"type"},{"location":"renderers/#Raytracing.FlatRenderer","page":"Renderers","title":"Raytracing.FlatRenderer","text":"FlatRenderer <: Renderer(\n    world::World = World()\n    background_color::RGB{Float32} = RGB{Float32}(0.0, 0.0, 0.0)\n)\n\nA «flat» renderer. This renderer estimates the solution of the rendering equation by neglecting  any contribution of the light. It just uses the pigment of each surface to  determine how to compute the final radiance.\n\nSee also: Renderer, World\n\n\n\n\n\n","category":"type"},{"location":"renderers/#Raytracing.PathTracer","page":"Renderers","title":"Raytracing.PathTracer","text":"PathTracer <: Renderer(\n        world::World, \n        background_color::RGB{Float32} = RGB{Float32}(0.0, 0.0, 0.0),\n        pcg::PCG = PCG(),\n        N::Int64 = 10,\n        max_depth::Int64 = 2,\n        russian_roulette_limit::Int64 = 3\n    )\n\nA simple path-tracing renderer.\n\nThe algorithm implemented here allows the caller to tune number  of rays thrown at each iteration, as well as the maximum depth.  It implements Russian roulette, so in principle it will take a  finite time to complete the calculation even if you set  max_depth to Inf.\n\nArguments\n\nworld::World : the world to be rendered\nbackground_color::RGB{Float32} : default background color  if the Ray doesn-t hit anything\npcg::PCG : PCG random number generator for evaluating integrals\nnum_of_rays::Int64 : number of Rays generated for each integral evaluation\nmax_depth::Int64 : maximal number recursive integrations\nrussian_roulette_limit::Int64: depth at whitch the Russian  Roulette algorithm begins\n\nSee also: Renderer, Ray, World, PCG\n\n\n\n\n\n","category":"type"},{"location":"renderers/#Raytracing.PointLightRenderer","page":"Renderers","title":"Raytracing.PointLightRenderer","text":"PointLightRenderer <: Renderer (\n    world::World,\n    background_color::RGB{Float32} = RGB{Float32}(0., 0., 0.),\n    ambient_color::RGB{Float32} = RGB{Float32}(0.1, 0.1, 0.1)\n)\n\nA simple point-light tracing renderer.\n\nArguments\n\nworld::World : the world to be rendered\nbackground_color::RGB{Float32} : default background color  if the Ray doesn-t hit anything\nambient_color::RGB{Float32} : default ambient color \n\nSee also: Renderer, World\n\n\n\n\n\n","category":"type"},{"location":"renderers/#Raytracing.is_point_visible","page":"Renderers","title":"Raytracing.is_point_visible","text":"is_point_visible(\n        world::World, \n        point::Point, \n        observer_pos::Point\n        ) :: Bool\n\nReturn true if the straight line connecting observer_pos to point do not intersect any of the shapes of world between the two points, otherwise return false.\n\nSee also: World, Point\n\n\n\n\n\n","category":"function"},{"location":"renderers/#Raytracing.quick_ray_intersection","page":"Renderers","title":"Raytracing.quick_ray_intersection","text":"quick_ray_intersection(shape::Shape, ray::Ray) :: Bool\n\nQuickly determine whether the ray hits the shape or not.\n\nSee also: Shape, Ray\n\n\n\n\n\nquick_ray_intersection(sphere::Sphere, ray::Ray) :: Bool\n\nQuickly checks if the ray intersects the sphere or not.\n\nSee also: Sphere, Ray\n\n\n\n\n\nquick_ray_intersection(plane::Plane, ray::Ray) :: Bool\n\nQuickly checks if the ray intersects the plane or not.\n\nSee also: Plane, Ray\n\n\n\n\n\n","category":"function"},{"location":"base_structs/","page":"Base Structs","title":"Base Structs","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"base_structs/#Base-Structs-and-functions-of-the-program","page":"Base Structs","title":"Base Structs and functions of the program","text":"","category":"section"},{"location":"base_structs/","page":"Base Structs","title":"Base Structs","text":"HDRimage \nto_RGB \nget_matrix\nParameters\nPoint\nVec\nNormal\nTransformation\nRay\nat\nCamera\nfire_ray\nImageTracer\nfire_all_rays!\nPigment\nBRDF\nMaterial\nShape\nVec2d\nHitRecord\nPointLight\nWorld\nadd_shape!\nadd_light!\nPCG\nrandom\ncreate_onb_from_z\nscatter_ray","category":"page"},{"location":"base_structs/#Raytracing.HDRimage","page":"Base Structs","title":"Raytracing.HDRimage","text":"HDRimage(\n    width::Int64\n    height::Int64\n    rgb_m::Array{RGB{Float32}} = fill(RGB(0.0, 0.0, 0.0), (width*height,))\n    )\n\nDefine a image in the format 2D  High-Dynamic-Range.\n\nArguments\n\nwidth::Float64 : width pixel number of the image\nheight::Float64 : height pixel number of the image\nrgb_m::Array{RGB{Float32}} : linearized color matrix;  the first element is the one in the bottom-left of the matrix,  then the line is read left-to-right and going to the upper row.\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.to_RGB","page":"Base Structs","title":"Raytracing.to_RGB","text":"to_RGB(r::Int64, g::Int64, b::Int64) :: RGB{Float32}\n\nReturn the RGB color with values inside the [0,1] interval.\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.get_matrix","page":"Base Structs","title":"Raytracing.get_matrix","text":"get_matrix(img::HDRimage) :: Matrix{RGB{Float32}}\n\nReturn the color matrix of the input img. The order of the pixel as they are stored in the HDRimage format is corrected in order to get the \"natural\" pixel matrix. \n\nSee also: HDRimage\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.Parameters","page":"Base Structs","title":"Raytracing.Parameters","text":"Parameters(\n    infile::String, \n    outfile::String,\n    a::Float64 = 0.18,\n    γ::Float64 = 1.0\n    )\n\nParameters passed from command line for the tone mapping.\n\nArguments\n\ninfile::String : input file name (must be a pfm)\noutfile::String : output file name (must be a png)\na::Float64 : parameter a for luminosity correction\nγ::Float64 : parameter γ for screen correction\n\nSee also: tone_mapping\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Point","page":"Base Structs","title":"Raytracing.Point","text":"Point(x::Float64, y::Float64, z::Float64)\n\nA point in 3D space.\n\nConstructors\n\nPoint() = new(0., 0. ,0.)\nPoint(x, y, z) = new(x, y, z)\nPoint(v::SVector{4, Float64}) = new(v[1], v[2], v[3])\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Vec","page":"Base Structs","title":"Raytracing.Vec","text":"Vec(x::Float64, y::Float64, z::Float64)\n\nA 3D Vector\n\nConstructors\n\nVec() = new(0., 0. ,0.)\nVec(x, y, z) = new(x, y, z)\nVec(P::Point) = new(P.x, P.y, P.z)\nVec(v::SVector{4, Float64}) = new(v[1], v[2], v[3])\nVec(N::Normal) = Vec(N.x, N.y, N.z)\n\nSee also: Normal\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Normal","page":"Base Structs","title":"Raytracing.Normal","text":"Normal(x::Float64, y::Float64, z::Float64)\n\nA normal vector in 3D space, you can give three components  and its struct normalize them.\n\nConstructors\n\nNormal(x,y,z) = new(x, y ,z)\nNormal(v::Vec) = new(v[1]/m, v[2]/m, v[3]/m)\nNormal(v::Vector{Float64}) = new(v[1]/m, v[2]/m, v[3]/m)\nNormal(v::SVector{4,Float64}) = new(v[1]/m, v[2]/m, v[3]/m)\n\n(m indicates the norm of the input vector)\n\nSee also: Vec\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Transformation","page":"Base Structs","title":"Raytracing.Transformation","text":"Transformation(M::SMatrix{4,4,Float64}, invM::SMatrix{4,4,Float64})\n\nContain two matrices 4x4 of Float64, one the inverse of the other. It's used to implement rotations, scaling and translations in 3D space  with homogenous formalism.\n\nNOTE: It does not check if invM is the inverse matrix of M, for computational efficiency purposes! In order to do that, looks at is_consistent(T::Transformation) function.\n\nConstructors\n\nTransformation(m, invm) = new(m, invm)\nTransformation() = new(            SMatrix{4,4}( Diagonal(ones(4)) ),             SMatrix{4,4}( Diagonal(ones(4)) )        )\n\nSee also: is_consistent\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Ray","page":"Base Structs","title":"Raytracing.Ray","text":"Ray(\n    origin::Point,\n    dir::Vec,\n    tmin::Float64 = 1e-5,\n    tmax::Float64 = Inf,\n    depth::Int64 = 0,\n    )\n\nA ray of light propagating in space.\n\nArguments\n\norigin::Point : origin of the ray\ndir::Vec : 3D direction along which this ray propagates\ntmin::Float64 : minimum distance travelled by the ray is this number times dir\ntmax::Float64 : maximum distance travelled by the ray is this number times dir\ndepth::Int64 : number of times this ray was reflected/refracted\n\nSee also: Point, Vec\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.at","page":"Base Structs","title":"Raytracing.at","text":"at(r::Ray, t::Float64) :: Point\n\nCompute the point along the ray's path at some distance from the origin.\n\nReturn a Point object representing the point in 3D space whose distance from the ray's origin is equal to t, measured in units of the length of Vec.dir.\n\nSee also: Ray, Point, Vec\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.Camera","page":"Base Structs","title":"Raytracing.Camera","text":"abstract type Camera end\n\nAn abstract type with the following concrete sub-types, defining different types of perspective projections:\n\nOrthogonalCamera\nPerspectiveCamera\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.fire_ray","page":"Base Structs","title":"Raytracing.fire_ray","text":"fire_ray(Ocam::OrthogonalCamera, u::Float64, v::Float64) :: Ray\nfire_ray(Pcam::PerspectiveCamera, u::Float64, v::Float64) :: Ray\nfire_ray(\n        ImTr::ImageTracer, \n        col::Int64, row::Int64, \n        u_px::Float64=0.5, v_px::Float64=0.5\n    ) :: Ray\n\nShoot one light Ray through the pixel (col, row) of ImTr.img image.  The parameters (col, row) are measured in a diffetent way compared to the HDRimage struct: here, the bottom left corner is placed at (0, 0). The following diagram shows the convenction for an image with dimensions (w,h):\n\n| (h,0)  (h,1)  (h,2)  ...  (h,w) |\n|  ...    ...    ...   ...   ...  |\n| (1,0)  (1,1)  (1,2)  ...  (1,w) |\n| (0,0)  (0,1)  (0,2)  ...  (0,w) |\n\nThe optional values u_px and v_px specify where the ray should cross the pixel; the convenction for their values are represented in the following  diagram as (u_px, v_px):\n\n(0, 1)                          (1, 1)\n    +------------------------------+\n    |                              |\n    |                              |\n    |                              |\n    +------------------------------+\n(0, 0)                          (1, 0)\n\nSee also: OrthogonalCamera, PerspectiveCamera, Ray, HDRimage, ImageTracer\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.ImageTracer","page":"Base Structs","title":"Raytracing.ImageTracer","text":"ImageTracer(\n    img::HDRimage,\n    cam::Camera,\n    samples_per_side::Int64 = 0,\n    pcg::PCG = PCG()\n    )\n\nImplement the \"screen\" of the observer.\n\nTrace an image by shooting light rays through each of its pixels.\n\nArguments\n\nimg::HDRimage : the image that will be rendered (required)\ncam::Camera : camera type of the observer (required)\nsamples_per_side::Int64 = 0 : if it is larger than zero, stratified sampling will  be applied to each pixel in the image, using the random number generator  pcg; if not, antialiasing will be ignored in fire_all_rays!\npcg::PCG = PCG() : PCG random number generator\n\nSee also: HDRimage,Camera, PCG, fire_ray, fire_all_rays!\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.fire_all_rays!","page":"Base Structs","title":"Raytracing.fire_all_rays!","text":"fire_all_rays!(\n        ImTr::ImageTracer, \n        func::Function, \n        callback::Union{Nothing, Function} = nothing,\n        callback_time_s::Float64 = 2.,\n        callback_kwargs::String\n        )\n\nShoot several light rays crossing each of the pixels in the ImTr.img image.\n\nFor each pixel in the HDRimage object fire one Ray, and pass it  to the function func, which must:\n\naccept a Ray as its only parameter \nreturn a RGB{Float32} color instance telling the color to  assign to that pixel in the image.\n\nIf callback is not nothing, it must be a function accepting at least two  parameters named col and row. This function is called periodically during the rendering, and the two mandatory  arguments are the row and column number of the last pixel that has been traced. \n\nPay Attention: Both the row and column are increased by one starting from zero: first the row and then the column.\n\nThe time between two consecutive calls to the callback can be tuned using the  parameter callback_time_s. Any keyword argument passed to fire_all_rays  is passed to the callback.\n\nSee also: Ray, HDRimage, ImageTracer\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.Pigment","page":"Base Structs","title":"Raytracing.Pigment","text":"abstract type Pigment end\n\nThis abstract class represents a pigment, i.e., a function that associates  a color with each point on a parametric surface (u,v). Call the function get_color to retrieve the color of the surface given a Vec2d object.\n\nThe concrete sub-types of this abstract class are:\n\nUniformPigment\nCheckeredPigment\nImagePigment\n\nSee also: Vec2d, get_color\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.BRDF","page":"Base Structs","title":"Raytracing.BRDF","text":"abstract type BRDF end\n\nAn abstract class representing a Bidirectional Reflectance Distribution Function. The concrete sub-types of this abstract class are:\n\nDiffuseBRDF\nSpecularBRDF\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Material","page":"Base Structs","title":"Raytracing.Material","text":"Material(\n    brdf::BRDF = DiffuseBRDF(),\n    emitted_radiance::Pigment = UniformPigment()\n)\n\nA struct representing a material.\n\nSee also: BRDF, DiffuseBRDF,  Pigment, UniformPigment \n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Shape","page":"Base Structs","title":"Raytracing.Shape","text":"abstract type Shape end\n\nAn abstract type with the following concrete sub-types, defining different types of shapes that can be created:\n\nSphere\nPlane\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.Vec2d","page":"Base Structs","title":"Raytracing.Vec2d","text":"Vec2d(u::Float64, v::Float64)\n\nA 2D vector used to represent a point on a surface. The fields are named u and v to distinguish them from the usual 3D coordinates x, y, z.\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.HitRecord","page":"Base Structs","title":"Raytracing.HitRecord","text":"HitRecord(\n    world_point::Point,\n    normal::Normal,\n    surface_point::Vec2d,\n    t::Float64,\n    ray::Ray,\n    shape::Union{Shape, Nothing} = nothing\n    )\n\nA struct holding information about a ray-shape intersection.\n\nArguments\n\nworld_point::Point: world coordinates of the hit point\nnormal::Normal: orientation of the normal to the surface where the hit happened\nsurface_point::Vec2d : position of the hit point on the surface of the object\nt::Float64 : distance from the origin of the ray where the hit happened\nray::Ray : the ray that hit the surface\nshape::Union{Shape, Nothing}: shape on which the hit happened, or nothing if no intersection happened\n\nSee also: Point, Normal, Vec2d Ray, Shape\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.PointLight","page":"Base Structs","title":"Raytracing.PointLight","text":"PointLight(p::Point, c::Color, r::Float64 = 0.0)\n\nA point light (used by the point-light renderer). This class holds information about a point light (a Dirac's delta in the  rendering equation).\n\nArguments\n\nposition::Point : position of the point light in 3D space\ncolor::RGB{Float32} : color of the point light\nlinear_radius::Float64: if non-zero, this «linear radius» r is  used to compute the solid angle subtended by the light at a given  distance d through the formula (r  d)^2.\n\nSee also: Point, PointLightRenderer\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.World","page":"Base Structs","title":"Raytracing.World","text":"World(\n    shapes::Array{Shape} = Array{Shape,1}(),\n    point_lights::Array{PointLight} = Array{PointLight,1}()\n)\n\nA struct holding a list of shapes, which make a «world».\n\nYou can add shapes to a world using add_shape!, and call  ray_intersection to check whether a light ray intersects any of  the shapes in the world.\n\nFor the PointLightRenderer algorithm, you can also add point-lights source using add_light!, and world will keep a list of all of them.\n\nSee also: Shape, add_shape!, PointLight, add_light, PointLightRenderer ray_intersection, Ray\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.add_shape!","page":"Base Structs","title":"Raytracing.add_shape!","text":"add_shape!(world::World, shape::Shape)\n\nAppend a new shape to the given world.\n\nSee also: Shape, World\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.add_light!","page":"Base Structs","title":"Raytracing.add_light!","text":"add_light!(world::World, pointlight::PointLight)\n\nAppend a new pointlight to the given world.\n\nSee also: PointLight, World\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.PCG","page":"Base Structs","title":"Raytracing.PCG","text":" PCG(state::UInt64 = UInt64(42), inc::UInt64 = UInt64(54))\n\nA mutable struct for the PCG Uniform Pseudo-random Number Generator.\n\nParameters\n\nstate::UInt64 = UInt64(42) : initial state number\ninc::UInt64 = UInt64(54) : initial sequence number\n\nReferences\n\nMelissa E. O’Neill (2014), \"PCG: A Family of Simple Fast  Space-Efficient Statistically Good Algorithms  for Random Number Generation\"\n\nSee also: random(pcg::PCG, ::Type{UInt32}),  random(pcg::PCG, ::Type{Float64})\n\n\n\n\n\n","category":"type"},{"location":"base_structs/#Raytracing.random","page":"Base Structs","title":"Raytracing.random","text":" random(pcg::PCG, ::Type{UInt32}) :: UInt32\n\nReturn a new random UInt32 number and advance PCG's internal state.\n\nThis function is based on the paper of Melissa E. O’Neill (2014),  where the Permuted Congruential Generator (PCG) family of random  number generators is defined and explained.\n\nReferences\n\nMelissa E. O’Neill (2014), \"PCG: A Family of Simple Fast  Space-Efficient Statistically Good Algorithms  for Random Number Generation\"\n\nSee also: random(pcg::PCG, ::Type{Float64}), PCG\n\n\n\n\n\n random(pcg::PCG, ::Type{Float64}) :: Float64\n\nReturns a Float64 random number inside [0,1] interval obtained  with a PCG Uniform Pseudo-random Number Generator.\n\nIt calls the random(pcg::PCG, ::Type{UInt32}) function, which returns a UInt32 random number, and divides it with typemax(UInt32).\n\nSee also: random(pcg::PCG, ::Type{UInt32}), PCG\n\n\n\n\n\n random(pcg::PCG) :: Float64\n\nReturns a Float64 random number inside [0,1] interval obtained  with a PCG Uniform Pseudo-random Number Generator.\n\nIt calls the random(pcg::PCG, ::Type{Float64}) function.\n\nSee also: random(pcg::PCG, ::Type{Float64}), random(pcg::PCG, ::Type{UInt32}), PCG\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.create_onb_from_z","page":"Base Structs","title":"Raytracing.create_onb_from_z","text":"create_onb_from_z(normal::Union{Vec, Normal}) :: (Normal, Normal, Normal)\n\nReturn an orthonormal base of 3 Normals with the z-axes  (i.e. the third Normal returned) parallel to the  input Vec/ Normal.\n\nThe implementation of this function is based on the paper of Duff et al. (2017), which improved the already efficient work made by Frisvad (2012).\n\nReferences\n\nDuff et al. (2017), \"Building an Orthonormal Basis,  Revisited\"\nFrisvad (2012), \"Building an Orthonormal Basis from a 3D  Unit Vector Without Normalization\"\n\nSee also: Vec, Normal\n\n\n\n\n\n","category":"function"},{"location":"base_structs/#Raytracing.scatter_ray","page":"Base Structs","title":"Raytracing.scatter_ray","text":"scatter_ray(\n    ::Type{DiffuseBRDF},\n    pcg::PCG, \n    incoming_dir::Vec, \n    interaction_point::Point, \n    normal::Normal, \n    depth::Int64,\n    ) :: Ray\n\nReturn a Ray scattered by a material with a DiffuseBRDF.\n\nA DiffuseBRDF has a uniform BRDF, i.e.  f_r(mathbfx mathbfPsirightarrowmathbfTheta) = rho_d  pi; the importance sampling for the PathTracer algorithm use consequently the  following PDF:\n\np(omega) propto \n    f_r(mathbfx mathbfPsirightarrowmathbfTheta)  cos(vartheta)\n    = fracrho_dpi  cos(vartheta) \n    propto cos(vartheta)\n\n    Rightarrow quad\np(omega) = fraccos(vartheta)pi \n    quad Rightarrow quad\np(vartheta varphi) = fraccos(vartheta)  sin(vartheta) 2pi\n\nRightarrow quad\nbeginaligned\n    p(vartheta) = 2  cos(vartheta)  sin(vartheta) \r\n    p(varphi  vartheta) = frac12 pi\nendaligned\n\nSee also: DiffuseBRDF, Ray, Vec,  Point, Normal, PCG\n\n\n\n\n\nscatter_ray(\n    ::Type{SpecularBRDF},\n    pcg::PCG, \n    incoming_dir::Vec, \n    interaction_point::Point, \n    normal::Normal, \n    depth::Int64,\n    ) :: Ray\n\nReturn a Ray scattered by a material with a SpecularBRDF.\n\nA SpecularBRDF has a Dirac delta BRDF, i.e.:\n\nf_r(mathbfx mathbfPsi rightarrow mathbfTheta) \n    propto \nfracdelta(sin^2theta_r - sin^2theta)  \n    delta(psi_r pm pi - psi)costheta\n\nThe importance sampling for the PathTracer algorithm use consequently the  following PDF:\n\np(omega) propto \n    f_r(mathbfx mathbfPsirightarrowmathbfTheta)  cos(vartheta)\n    propto frac1cos(vartheta)  cos(vartheta) \n    propto cost\n\nSee also: SpecularBRDF, Ray, Vec,  Point, Normal, PCG\n\n\n\n\n\n","category":"function"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"shapes/#Avaiable-shapes","page":"Avaiable Shapes","title":"Avaiable shapes","text":"","category":"section"},{"location":"shapes/#Sphere","page":"Avaiable Shapes","title":"Sphere","text":"","category":"section"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"Sphere\nsphere_point_to_uv\nsphere_normal\nray_intersection(sphere::Sphere, ray::Ray)","category":"page"},{"location":"shapes/#Raytracing.Sphere","page":"Avaiable Shapes","title":"Raytracing.Sphere","text":"Sphere <: Shape(\n    T::Transformation = Transformation(),\n    Material::Material = Material()\n)\n\nA 3D unit sphere, i.e. centered on the origin of the axes and with radius 1.0.\n\nArguments\n\nT::Transformation : transformation associated to the sphere.\nMaterial::Material : material that constitutes the sphere.\n\nSee also: Shape, Transformation, Material\n\n\n\n\n\n","category":"type"},{"location":"shapes/#Raytracing.sphere_point_to_uv","page":"Avaiable Shapes","title":"Raytracing.sphere_point_to_uv","text":"sphere_point_to_uv(point::Point) :: Vec2d\n\nConvert a 3D point P = (P_x P_y P_z) on the surface of the unit sphere into a 2D Vec2d using the following spherical coordinates:\n\nu = fracphi2pi = fracarctan (P_y  P_x)2pi \n    quad \nv = fracthetapi = fracarccos (P_z)pi\n\nSee also: Point, Vec2d, Sphere\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.sphere_normal","page":"Avaiable Shapes","title":"Raytracing.sphere_normal","text":"sphere_normal(point::Point, ray_dir::Vec) :: Normal\n\nCompute the Normal of a unit sphere.\n\nThe normal is computed for the given Point point = (P_x P_y P_z)  (with sqrtP_x^2 + P_y^2 + P_z^2=1) on the  surface of the sphere, and it is chosen so that it is always in the opposite direction with respect to the given Vec ray_dir.\n\nSee also: Point, Ray, Normal, Sphere\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.ray_intersection-Tuple{Sphere,Ray}","page":"Avaiable Shapes","title":"Raytracing.ray_intersection","text":"ray_intersection(sphere::Sphere, ray::Ray) :: Union{HitRecord, Nothing}\n\nCheck if the ray intersects the sphere. Return a HitRecord, or nothing if no intersection is found.\n\nSee also: Ray, Sphere, HitRecord\n\n\n\n\n\n","category":"method"},{"location":"shapes/#Plane","page":"Avaiable Shapes","title":"Plane","text":"","category":"section"},{"location":"shapes/","page":"Avaiable Shapes","title":"Avaiable Shapes","text":"Plane\nplane_point_to_uv\nplane_normal\nray_intersection(plane::Plane, ray::Ray)","category":"page"},{"location":"shapes/#Raytracing.Plane","page":"Avaiable Shapes","title":"Raytracing.Plane","text":"Plane <: Shape(\n    T::Transformation = Transformation(),\n    Material::Material = Material()\n)\n\nA 3D unit plane, i.e. the x-y plane (set of 3D points with z=0).\n\nArguments\n\nT::Transformation : transformation associated to the plane.\nMaterial::Material : material that constitutes the plane.\n\nSee also: Shape, Transformation, Material\n\n\n\n\n\n","category":"type"},{"location":"shapes/#Raytracing.plane_point_to_uv","page":"Avaiable Shapes","title":"Raytracing.plane_point_to_uv","text":"plane_point_to_uv(point::Point) :: Vec2d\n\nConvert a 3D point P = (P_x P_y P_z) on the surface of the unit plane into a 2D Vec2d using the following periodical coordinates:\n\nu = P_x - lfloor P_x rfloor\n    quad \nv = P_y - lfloor P_y rfloor\n\nwhere lfloor cdot rfloor indicates the rounding down approximation, in order to guarantee that u v in 0 1).\n\nSee also: Point, Vec2d, Plane\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.plane_normal","page":"Avaiable Shapes","title":"Raytracing.plane_normal","text":"plane_normal(point::Point, ray_dir::Vec) :: Normal\n\nCompute the Normal of a unit plane.\n\nThe normal is computed for the given Point point = (P_x P_y 0) on the  surface of the plane, and it is chosen so that it is always in the opposite direction with respect to the given Vec ray_dir.\n\nSee also: Point, Ray, Normal, Plane\n\n\n\n\n\n","category":"function"},{"location":"shapes/#Raytracing.ray_intersection-Tuple{Plane,Ray}","page":"Avaiable Shapes","title":"Raytracing.ray_intersection","text":"ray_intersection(plane::Plane, ray::Ray) :: Union{HitRecord, Nothing}\n\nCheck if the ray intersects the plane. Return a HitRecord, or nothing if no intersection is found.\n\nSee also: Ray, Plane, HitRecord\n\n\n\n\n\n","category":"method"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"transformations/#Transformations","page":"Transformations","title":"Transformations","text":"","category":"section"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"rotation_x\nrotation_y\nrotation_z\nscaling\ntranslation\ninverse\nis_consistent","category":"page"},{"location":"transformations/#Raytracing.rotation_x","page":"Transformations","title":"Raytracing.rotation_x","text":"rotation_x(ϑ::Float64) :: Transformation\n\nEncoding a rotation around the x-axis of an angle ϑ in radiant. \n\nThe positive sign is given by the right-hand rule, therefore clockwise rotation for entering x-axis corresponds to a ϑ>0 rotation angle. \n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.rotation_y","page":"Transformations","title":"Raytracing.rotation_y","text":"rotation_y(ϑ::Float64) :: Transformation\n\nEncoding a rotation around the y-axis of an angle ϑ in radiant. \n\nThe positive sign is given by the right-hand rule, therefore clockwise rotation for entering y-axis corresponds to a ϑ>0 rotation angle. \n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.rotation_z","page":"Transformations","title":"Raytracing.rotation_z","text":"rotation_z(ϑ::Float64) :: Transformation\n\nEncoding a rotation around the z-axis of an angle ϑ in radiant. \n\nThe positive sign is given by the right-hand rule, therefore clockwise rotation for entering z-axis corresponds to a ϑ>0 rotation angle. \n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.scaling","page":"Transformations","title":"Raytracing.scaling","text":"scaling(v::Vec) :: Transformation\n\nEncoding a scaling of the 3 spatial coordinates according to the vector v (negative values codify spatial reflections). \n\nEach component of  v must be different from zero.\n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.translation","page":"Transformations","title":"Raytracing.translation","text":"translation(v::Vec) :: Transformation\n\nEncoding a rigid translation of the 3 spatial coordinates according to the vector v, which specifies the amount of shift to be applied along the three axes.\n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.inverse","page":"Transformations","title":"Raytracing.inverse","text":"inverse(T::Transformation) :: Transformation\n\nReturn the inverse affine transformation of T. This method is very cheap to call.\n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Raytracing.is_consistent","page":"Transformations","title":"Raytracing.is_consistent","text":"is_consistent(T::Transformation) :: Bool\n\nCheck the internal consistency of the  input transformation,  returning a bool variable indicating whether T.M==T.invM. This method is useful when writing tests.\n\nSee also: Transformation\n\n\n\n\n\n","category":"function"},{"location":"brdfs_and_pigments/","page":"BRDFs and Pigments","title":"BRDFs and Pigments","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"brdfs_and_pigments/#BRDFs-and-Pigments","page":"BRDFs and Pigments","title":"BRDFs and Pigments","text":"","category":"section"},{"location":"brdfs_and_pigments/","page":"BRDFs and Pigments","title":"BRDFs and Pigments","text":"UniformPigment\nCheckeredPigment\nImagePigment\nDiffuseBRDF\nSpecularBRDF","category":"page"},{"location":"brdfs_and_pigments/#Raytracing.UniformPigment","page":"BRDFs and Pigments","title":"Raytracing.UniformPigment","text":"UniformPigment <: Pigment(\n    color::RGB{Float32} = RGB{Float32}(0.0, 0.0, 0.0)\n)\n\nA uniform pigment. This is the most boring pigment: a uniform hue over the whole surface.\n\nSee also: Pigment\n\n\n\n\n\n","category":"type"},{"location":"brdfs_and_pigments/#Raytracing.CheckeredPigment","page":"BRDFs and Pigments","title":"Raytracing.CheckeredPigment","text":"CheckeredPigment <: Pigment\n    color1::RGB{Float32} = RGB{Float32}(1.0, 1.0, 1.0),\n    color2::RGB{Float32} = RGB{Float32}(0.0, 0.0, 0.0),\n    num_steps::Int64 = 2\n)\n\nA checkered pigment. The number of rows/columns in the checkered pattern is tunable through the integer value num_steps, but you cannot have a different number of  repetitions along the u/v directions.\n\nSee also: Pigment\n\n\n\n\n\n","category":"type"},{"location":"brdfs_and_pigments/#Raytracing.ImagePigment","page":"BRDFs and Pigments","title":"Raytracing.ImagePigment","text":"ImagePigment <: Pigment(\n    image::HDRimage = HDRimage(3, 2, fill( BLACK, (6,) ) )\n)\n\nA textured pigment. The texture is given through a PFM image.\n\nSee also: Pigment, HDRimage\n\n\n\n\n\n","category":"type"},{"location":"brdfs_and_pigments/#Raytracing.DiffuseBRDF","page":"BRDFs and Pigments","title":"Raytracing.DiffuseBRDF","text":"DiffuseBRDF <: BRDF(\n    pigment::Pigment = UniformPigment(RGB{Float32}(1.0, 1.0, 1.0)),\n    reflectance::Float64 = 1.0\n)\n\nA class representing an ideal diffuse BRDF (also called «Lambertian»).\n\nSee also: Pigment, UniformPigment\n\n\n\n\n\n","category":"type"},{"location":"brdfs_and_pigments/#Raytracing.SpecularBRDF","page":"BRDFs and Pigments","title":"Raytracing.SpecularBRDF","text":"DiffuseBRDF <: BRDF(\n    pigment::Pigment = UniformPigment(RGB{Float32}(1.0, 1.0, 1.0)),\n    theresold_angle_rad::Float64 = π/180.\n)\n\nA class representing an ideal mirror BRDF.\n\nSee also: Pigment, UniformPigment\n\n\n\n\n\n","category":"type"},{"location":"reading_and_writing/","page":"Reading and Writing","title":"Reading and Writing","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"reading_and_writing/#Reading-and-Writing","page":"Reading and Writing","title":"Reading and Writing","text":"","category":"section"},{"location":"reading_and_writing/","page":"Reading and Writing","title":"Reading and Writing","text":"parse_command_line\nparse_demo_settings\nparse_tonemapping_settings\nparse_demoanimation_settings\nload_image\nRaytracing.ldr2pfm","category":"page"},{"location":"reading_and_writing/#Raytracing.parse_command_line","page":"Reading and Writing","title":"Raytracing.parse_command_line","text":"parse_command_line(args::Vector{String}) :: \n    (String, String, Float64, Float64)\n\nInterpret the command line when the main is executed,  and manage eventual argument errors.\n\nInput\n\nA args::Vector{String}) with length 2, 3 or 4.\n\nReturns\n\nA tuple (infile, outfile, a, γ) containing:\n\ninfile::String : first string (required), is the input file  name, which must be a PFM format.\noutfile::String : second string (required), is the output filename;  its format can be PNG or TIFF.\na::Float64 : third argument (optional), is the scale factor for  luminosity correction (default 0.18), passed to normalize_image!\nγ::Float64 : fourth argument (optional), is the gamma factor for  screen correction (default 1.0), passed to γ_correction!\n\nSee also : normalize_image!, γ_correction!\n\n\n\n\n\n","category":"function"},{"location":"reading_and_writing/#Raytracing.parse_tonemapping_settings","page":"Reading and Writing","title":"Raytracing.parse_tonemapping_settings","text":"parse_tonemapping_settings(dict::Dict{String, Any}) \n    :: (String, String, Float64, Float64)\n\nParse a Dict{String, T} where {T} for the tone_mapping function.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (pfm, png, a, γ) containing:\n\npfm::String = dict[\"pfm_infile\"] : input pfm filename (required)\npng::String = dict[\"outfile\"] : output LDR filename (required)\na::Float64 = dict[\"alpha\"] : scale factor (default = 0.18)\nγ::Float64 = dict[\"gamma\"] : gamma factor (default = 1.0)\n\nSee also:  tone_mapping\n\n\n\n\n\n","category":"function"},{"location":"reading_and_writing/#Raytracing.load_image","page":"Reading and Writing","title":"Raytracing.load_image","text":"load_image(path::String) :: HDRimage\n\nLoad an image from the specified path in an HDR image format.\n\nSee also: HDRimage\n\n\n\n\n\n","category":"function"},{"location":"reading_and_writing/#Raytracing.ldr2pfm","page":"Reading and Writing","title":"Raytracing.ldr2pfm","text":"ldr2pfm(path::String, outfile::String)\n\nLoad an image from the specified path, convert it in a pfm file format and save it as outfile. It works through the load_image and the  write(::IO, ::HDRimage) function.\n\nSee also: HDRimage, load_image,   write(::IO, ::HDRimage)\n\n\n\n\n\n","category":"function"},{"location":"demo_animation/","page":"Demo animation","title":"Demo animation","text":"DocTestSetup = quote\r\n    using Raytracing\r\nend","category":"page"},{"location":"demo_animation/#Demo","page":"Demo animation","title":"Demo","text":"","category":"section"},{"location":"demo_animation/","page":"Demo animation","title":"Demo animation","text":"demo_animation\r\nparse_demoanimation_settings","category":"page"},{"location":"demo_animation/#Raytracing.demo_animation","page":"Demo animation","title":"Raytracing.demo_animation","text":"demo_animation( \n\t\tcamera_type::String = \"per\",\n\t\talgorithm::String = \"flat\",\n    \t\twidth::Int64 = 200, \n    \t\theight::Int64 = 150,\n\t\tworld_type::String = \"A\",\n   \t\tanim_output::String = \"demo-animation.mp4\",\n\t)\n\nCreates an animation of the demo image with the specified options. It's necessary to have istalled the ffmpeg software to run this function.\n\nThis function works following this steps:\n\ncreates an hidden directory, called \".wip_animation\"; if it already exists, it will be destroyed and recreated.\ninside \".wpi_animation\", creates 360 png images of the demo image (using the  demo function with the specified projection, algorithm and image  dims); each image correspons to a frame of the future animation\nthrough the ffmpeg software, the 360 png images are converted into the animation mp4 file, and saved in the main directory\nthe \".wpi_animation\" directory and all the png images inside it are destroyed\n\nArguments\n\ncamera_type::String = \"per\" : set the perspective projection view:\n\n\t- `camera_type==\"per\"` -> set [`PerspectiveCamera`](@ref)  (default value)\n\t- `camera_type==\"ort\"`  -> set [`OrthogonalCamera`](@ref)\n\nalgorithm::String = \"flat\" : algorithm to be used in the rendered:\nalgorithm==\"onoff\" -> OnOffRenderer algorithm \nalgorithm==\"flat\" -> FlatRenderer algorithm (default value)\nalgorithm==\"pathtracing\" -> PathTracer algorithm\nalgorithm==\"pointlight\" -> PointLightRenderer algorithm\nwidth::Int64 = 640 and height::Int64 = 480 : pixel dimensions of the demo image\nworld_type::String = \"A\" : specifies the type of world to be rendered (\"A\", \"B\" or \"C\")\nanim_output::String = \"demo-animation.mp4\" : name of the output animation file\nsamples_per_pixel::Int64 = 0 : number of rays per pixel to be used (antialiasing)\n\nSee also: OnOffRenderer, FlatRenderer,  PathTracer, demo\n\n\n\n\n\n","category":"function"},{"location":"demo_animation/#Raytracing.parse_demoanimation_settings","page":"Demo animation","title":"Raytracing.parse_demoanimation_settings","text":"parse_demoanimation_settings(dict::Dict{String, T}) where {T}\n    :: (String, String, Int64, Int64, String, String, Int64)\n\nParse a Dict{String, T} where {T} for the demo_animation function.\n\nInput\n\nA dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (ct, al, w, h, wt, anim, spp) containing the following variables; the corresponding keys are also showed:\n\nct::String = dict[\"camera_type\"] : set the perspective projection view:\n\n\t- `ct==\"per\"` -> set [`PerspectiveCamera`](@ref)  (default value)\n\t- `ct==\"ort\"`  -> set [`OrthogonalCamera`](@ref)\n\nal::String = dict[\"algorithm\"] : algorithm to be used in the rendered:\nal==\"onoff\" -> OnOffRenderer algorithm \nal==\"flat\" -> FlatRenderer algorithm (default value)\nal==\"pathtracing\" -> PathTracer algorithm \nalgorithm==\"pointlight\" -> PointLightRenderer algorithm\nw::Int64 = dict[\"width\"] : number of pixels on the horizontal axis to be rendered \nh::Int64 = dict[\"height\"] : width and height of the rendered image\nwt::String = dict[\"world_type\"] : type of the world to be rendered\nanim::String = dict[\"set_anim_name\"] : output animation name\nspp::Int64  = dict[\"samples_per_pixel\"] : number of ray to be  generated for each pixel\n\nSee also:  demo_animation, demo\n\n\n\n\n\n","category":"function"},{"location":"cameras/","page":"Cameras","title":"Cameras","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"cameras/#Cameras","page":"Cameras","title":"Cameras","text":"","category":"section"},{"location":"cameras/","page":"Cameras","title":"Cameras","text":"OrthogonalCamera\nPerspectiveCamera","category":"page"},{"location":"cameras/#Raytracing.OrthogonalCamera","page":"Cameras","title":"Raytracing.OrthogonalCamera","text":"OrthogonalCamera <: Camera (\n    a::Float64 = 1.0,\n    T::Transformation = Transformation()\n)\n\nA camera implementing an orthogonal 3D → 2D projection. This class implements an observer seeing the world through an orthogonal projection.\n\nArguments\n\na::Float64 : aspect ratio, defines how larger than the height is the image.  For fullscreen images, you should probably set a to 16/9, as this is the  most used aspect ratio used in modern monitors.\nT::Transformation : transformation that defines the position of the observer.\n\nSee also: Transformation, Camera\n\n\n\n\n\n","category":"type"},{"location":"cameras/#Raytracing.PerspectiveCamera","page":"Cameras","title":"Raytracing.PerspectiveCamera","text":"PerspectiveCamera <: Camera (\n    d::Float64 = 1.0,\n    a::Float64 = 1.0,\n    T::Transformation = Transformation()\n    )\n\nA camera implementing a perspective 3D → 2D projection. This class implements an observer seeing the world through a perspective projection.\n\nArguments\n\nd::Float64: distance between the observer and the screen, it influences  the so-called «aperture» (the field-of-view angle along the horizontal direction).\na::Float64 : aspect ratio, defines how larger than the height is the image.  For fullscreen images, you should probably set a to 16/9, as this is the  most used aspect ratio used in modern monitors.\nT::Transformation : transformation that defines the position of the observer.\n\nSee also: Transformation, Camera\n\n\n\n\n\n","category":"type"},{"location":"tone_mapping/","page":"Tone Mapping","title":"Tone Mapping","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"tone_mapping/#Tone-Mapping","page":"Tone Mapping","title":"Tone Mapping","text":"","category":"section"},{"location":"tone_mapping/","page":"Tone Mapping","title":"Tone Mapping","text":"luminosity\nlum_max\navr_lum\nclamp\nnormalize_image!\nclamp_image!\nγ_correction!\ntone_mapping\nparse_tonemapping_settings","category":"page"},{"location":"tone_mapping/#Raytracing.luminosity","page":"Tone Mapping","title":"Raytracing.luminosity","text":"luminosity(c::RGB{T}) :: Float64\n\nReturn the best average luminosity of a color c = (R_i G_i B_i), through the Shirley & Morley proposal:\n\nl_i = fracmaxR_i G_i B_i  + minR_i G_i B_i 2\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.lum_max","page":"Tone Mapping","title":"Raytracing.lum_max","text":"lum_max(img::HDRimage) :: Float64\n\nReturn the maximum luminosity of the given img according to the luminosity function of a color.\n\nSee also: HDRimage, luminosity\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.normalize_image!","page":"Tone Mapping","title":"Raytracing.normalize_image!","text":"normalize_image!(  \n        img::HDRimage, \n        a::Float64 = 0.18,\n        lum::Union{Number, Nothing} = nothing, \n        δ::Number = 1e-10\n        )\n\nNormalize the img colors through the following formula: \n\nforall  mathrmcolors  c =(R_i G_i B_i)  \nmathrmof  the  image   \r\n\nX_i rightarrow fracalangle l rangle X_i \n    quad  quad  \nforall X_i = R_i G_i B_i \n\nwhere langle l rangle is the average luminosity returned by the avg_lum function. \n\nSee also: HDRimage, avg_lum\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.clamp_image!","page":"Tone Mapping","title":"Raytracing.clamp_image!","text":"clamp_image!(img::HDRimage)\n\nAdjust the color levels of the brightest pixels in the img through the clamp function.\n\nSee also: HDRimage, clamp\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.γ_correction!","page":"Tone Mapping","title":"Raytracing.γ_correction!","text":"γ_correction!(img::HDRimage, γ::Float64=1.0, k::Float64=1.0)\n\nCorrects the image using the γ factor, assuming a potential dependence  between the input and output signals of a monitor/screen. \n\nAs third optional argument, you can pass the maximum value 'k' of the range  you want the RGB colors may have. The default value is 'k=1.0', so the range  RGB colors can span is '[0.0, 1.0]'\n\nSee also: HDRimage\n\n\n\n\n\n","category":"function"},{"location":"tone_mapping/#Raytracing.tone_mapping","page":"Tone Mapping","title":"Raytracing.tone_mapping","text":"Tone-map the given input pfm file infile with luminosity normalisation a and gamma factor γ. Return a file with the input outfile name outfile and  of the specified LDR format, if possible.\n\nIn order to do the tone-mapping, this function relies on the following three function, called in the presented order:\n\nnormalize_image! : normalize the image colors\nclamp_image! : adjust the color levels of the brightest pixels\nγ_correction! : corrects the image using the γ factor\n\nSee also: normalize_image!, clamp_image!, γ_correction!\n\n\n\n\n\n","category":"function"},{"location":"","page":"Introduction","title":"Introduction","text":"DocTestSetup = quote\r\n    using Raytracing\r\nend","category":"page"},{"location":"#Raytracer.jl-:-an-implementation-of-a-raytracing-program-in-Julia","page":"Introduction","title":"Raytracer.jl : an implementation of a raytracing program in Julia","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"This is the documentation of Raytracing.jl package, an implementation of a raytracing program written in Julia.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"This program has various features: it can generate simple fotorealistic images and animations, read and write High Dynamic Range images in PFM format and manipulate them throug a tone mapping algorithm.","category":"page"},{"location":"#Demo","page":"Introduction","title":"Demo","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Demo demo is the function that allows you to appreciate what type of image Raytracing.jl can create. It has two principal scenaries: one very simple used to better understand how every renderer implemented work and see an exemlpe of animation, the other, the other uses most of the shapes and \"material\" imlpemented. You can both use the function with the default parameters or choose them to directly see functioning of each variable.","category":"page"},{"location":"#Demo-animation","page":"Introduction","title":"Demo animation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Demo animation is a function showing a simple rotation of 360° around ten spheres (eight on the vertices of a cube and two on two surfaces). Uses ffmpeg software to generate a video (in .gif or .mp4 format).","category":"page"},{"location":"#Reading,-writing-and-tone-mapping-PFM-image","page":"Introduction","title":"Reading, writing and tone mapping PFM image","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"A useful features not only generating images but also as a mid step between the generation and the \"public\" visualization of an image is the possybility of saving a raw image and modify it. Following this pilosophy, after the generation two extension of the image are saved: .pfm and .png. If the luminosity or the color saturation doesn't correspond to your tastes or doesn't fit the color trait of your screen, you don't have to re-generate the whole image, but just need to find the best parameters to use in the tone mapping algorithm.","category":"page"},{"location":"#Documentation","page":"Introduction","title":"Documentation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The documentation was built using Documenter.jl.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Dates # hide\r\nprintln(\"Documentation built on $(now()) using Julia $(VERSION).\") # hide","category":"page"},{"location":"#Contents","page":"Introduction","title":"Contents","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"#Index","page":"Introduction","title":"Index","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"demo/","page":"Demo","title":"Demo","text":"DocTestSetup = quote\n    using Raytracing\nend","category":"page"},{"location":"demo/#Demo","page":"Demo","title":"Demo","text":"","category":"section"},{"location":"demo/","page":"Demo","title":"Demo","text":"demo\nfirst_world\nsecond_world\nselect_world\nparse_demo_settings","category":"page"},{"location":"demo/#Raytracing.demo","page":"Demo","title":"Raytracing.demo","text":"demo(\n      camera_type::String = \"per\",\n\tcamera_position::Point = Point(-1.,0.,0.), \n\talgorithm::String = \"flat\",\n      α::Float64 = 0., \n      width::Int64 = 640, \n      height::Int64 = 480, \n      pfm_output::String = \"demo.pfm\", \n      png_output::String = \"demo.png\",\n\tbool_print::Bool = true,\n\tbool_savepfm::Bool = true,\n\tworld_type::String = \"A\",\n\tinit_state::Int64 = 45,\n\tinit_seq::Int64 = 54,\n\tsamples_per_pixel::Int64 = 0\n      )\n\nCreates a demo image with the specified options. \n\nThere are two possible demo image \"world\" to be rendered, specified through the input string type.\n\nThe type==\"A\" demo image world consist in a set of 10 spheres of equal radius 0.1: 8 brown spheres are placed at the verteces of a cube of side 1.0, one green-purple  checked sphere is in the center of the lower cube face and another multi-colored sphere is in the center of the left cube face.\n\nThe type==\"B\" demo image world consists in a checked x-y plane, a blue opaque  sphere, a red reflecting sphere, and a green oblique reflecting plane, all inside a giant emetting sphere.\n\nThe type==\"C\" demo image world consists in... discover yourself!\n\nThe creation of the demo image has the objective to check the correct behaviour of the rendering software, specifically the orientation upside-down and left-right.\n\nArguments\n\ncamera_type::String = \"per\" : set the perspective projection view:\n\n\t- `camera_type==\"per\"` -> set [`PerspectiveCamera`](@ref)  (default value)\n\t- `camera_type==\"ort\"`  -> set [`OrthogonalCamera`](@ref)\n\ncamera_position::Point = Point(-1.,0.,0.) : set the point of observation  in (X,Y,Z`) coordinates\nalgorithm::String = \"flat\" : algorithm to be used in the rendered:\nalgorithm==\"onoff\" -> OnOffRenderer algorithm \nalgorithm==\"flat\" -> FlatRenderer algorithm (default value)\nalgorithm==\"pathtracing\" -> PathTracer algorithm \nalgorithm==\"pointlight\" -> PointLightRenderer algorithm\nα::Float64 = 0. : angle of rotation IN RADIANTS, relative to the vertical (i.e. z) axis, of the view direction\nwidth::Int64 = 640 and height::Int64 = 480 : pixel dimensions of the demo image\npfm_output::String = \"demo.pfm\" : name of the output pfm file\npng_output::String = \"demo.png\" : name of the output LDR file\nbool_print::Bool = true : specifies if the WIP messages of the demo function should be printed or not (useful option for demo_animation)\nbool_savepfm::Bool = true : bool that specifies if the pfm file should be saved or not (useful option for demo_animation)\nworld_type::String = \"A\" : specifies the type of world to be rendered (\"A\", \"B\" or \"C\")\ninit_state::Int64 = 45 : initial state of the PCG random number generator\ninit_seq::Int64 = 54 : initial sequence of the PCG random number generator\nsamples_per_pixel::Int64 = 0 : number of rays per pixel to be used (antialiasing)\n\nSee also: Point ,OnOffRenderer, FlatRenderer,  PathTracer, demo_animation\n\n\n\n\n\n","category":"function"},{"location":"demo/#Raytracing.first_world","page":"Demo","title":"Raytracing.first_world","text":"first_world() :: World\n\nRender the first world (identified with the string \"A\").\n\nThis world consists in a set of 10 spheres of equal radius 0.1: 8 brown spheres are placed at the verteces of a cube of side 1.0, one green-purple  checked sphere is in the center of the lower cube face and another multi-colored sphere is in the center of the left cube face.\n\nSee also: World, demo, demo_animation\n\n\n\n\n\n","category":"function"},{"location":"demo/#Raytracing.second_world","page":"Demo","title":"Raytracing.second_world","text":"second_world() :: World\n\nRender the second world (identified with the string \"B\").\n\nThis world consists in a checked x-y plane, a blue opaque  sphere, a red reflecting sphere, and a green oblique reflecting plane, all inside a giant emetting sphere.\n\nSee also: World, demo, demo_animation\n\n\n\n\n\n","category":"function"},{"location":"demo/#Raytracing.select_world","page":"Demo","title":"Raytracing.select_world","text":"select_world(type_world::String) ::Function\n\nSelect which demo world is used\n\n\n\n\n\n","category":"function"},{"location":"demo/#Raytracing.parse_demo_settings","page":"Demo","title":"Raytracing.parse_demo_settings","text":"parse_demo_settings(dict::Dict{String, Any}) \n    :: (\n        String, Point, String, Float64, Int64, Int64, String, String,\n        Bool, Bool, String, Int64, Int64, Int64\n        )\n\nParse a Dict{String, T} where {T} for the demo function.\n\nInput\n\nA `dict::Dict{String, T} where {T}\n\nReturns\n\nA tuple (ct, cp, al, α, w, h, pfm, png, bp, bs, wt, ist, ise, spp) containing the following variables; the corresponding keys are also showed:\n\nct::String = dict[\"camera_type\"] : set the perspective projection view:\nct==\"per\" -> set PerspectiveCamera  (default value)\nct==\"ort\"  -> set OrthogonalCamera\ncp::String = dict[\"camera_position\"] : \"X,Y,Z\" coordinates of the  choosen observation point of view \nal::String = dict[\"algorithm\"] : algorithm to be used in the rendered:\nal==\"onoff\" -> OnOffRenderer algorithm \nal==\"flat\" -> FlatRenderer algorithm (default value)\nal==\"pathtracing\" -> PathTracer algorithm \nalgorithm==\"pointlight\" -> PointLightRenderer algorithm\nα::String = dict[\"alpha\"] : choosen angle of rotation respect to vertical  (i.e. z) axis\nw::Int64 = dict[\"width\"] : number of pixels on the horizontal axis to be rendered\nh::Int64 = dict[\"height\"] : number of pixels on the vertical axis to be rendered \npfm::String = dict[\"set_pfm_name\"] : output pfm filename\npng::String = dict[\"setpngname\"]` : output LDR filename\nbp::Bool = dict[\"bool_print\"] : if true, WIP message of demo  function are printed (otherwise no)\nbs::Bool = dict[\"bool_savepfm\"] : if true, demo function saves the  pfm file to disk\nwt::String = dict[\"world_type\"] : type of the world to be rendered\nist::Int64 = dict[\"init_state\"] : initial state of the PCG generator\nise::Int64 = dict[\"init_seq\"] : initial sequence of the PCG generator\nspp::Int64  = dict[\"samples_per_pixel\"] : number of ray to be  generated for each pixel\n\nSee also:  demo, Point, PCG\n\n\n\n\n\n","category":"function"}]
}
